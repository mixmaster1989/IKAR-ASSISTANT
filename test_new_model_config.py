#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª—å—é openai/gpt-oss-20b:free –∏ fallback
"""

import asyncio
import sys
import os

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
def load_env_file(env_path: str = ".env"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞"""
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–∞–º–∏
load_env_file()

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ backend –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

from backend.config import LLM_CONFIG
from backend.llm.openrouter import OpenRouterClient
from backend.utils.logger import get_logger

logger = get_logger('new_model_test')

async def test_new_model_config():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å fallback –º–æ–¥–µ–ª—å—é"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏")
    print(f"üìã –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å: {LLM_CONFIG.get('model', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞')}")
    print(f"üîÑ Fallback –º–æ–¥–µ–ª—å: {LLM_CONFIG.get('fallback_model', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞')}")
    print()
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
        client = OpenRouterClient()
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        test_prompt = "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞? –î–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç."
        
        print("üöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å...")
        response = await client.generate_response(test_prompt)
        print(f"‚úÖ –û—Ç–≤–µ—Ç: {response[:100]}...")
        print()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º fallback –º–æ–¥–µ–ª–∏
        print("üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º fallback –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é...")
        fallback_response = await client.generate_response(
            test_prompt, 
            model=LLM_CONFIG.get('fallback_model')
        )
        print(f"‚úÖ Fallback –æ—Ç–≤–µ—Ç: {fallback_response[:100]}...")
        print()
        
        print("üéâ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = asyncio.run(test_new_model_config())
    sys.exit(0 if success else 1) 