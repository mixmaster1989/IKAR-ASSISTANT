# üîß –†–ï–®–ï–ù–ò–ï: –ü–ê–†–°–ò–ù–ì JAVASCRIPT-HEAVY –Ø–ù–î–ï–ö–°.–£–°–õ–£–ì–ò

## üéØ –ü–†–û–ë–õ–ï–ú–ê:
–Ø–Ω–¥–µ–∫—Å.–£—Å–ª—É–≥–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∑–∞–∫–∞–∑—ã —á–µ—Ä–µ–∑ JavaScript, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ–π BeautifulSoup –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç.

## ‚úÖ –†–ï–®–ï–ù–ò–ï: 2 –†–ê–ë–û–ß–ò–• –í–ê–†–ò–ê–ù–¢–ê

### –í–ê–†–ò–ê–ù–¢ 1: Playwright (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø) ‚ö° –ë–´–°–¢–†–û
**–ü–æ—á–µ–º—É:** 2.3x –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º Selenium, –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏, –ª—É—á—à–µ –¥–ª—è JS-—Å–∞–π—Ç–æ–≤[88][89][91][92]

**–ü–ª—é—Å—ã:**
- 2-3x –±—ã—Å—Ç—Ä–µ–µ —á–µ–º Selenium –Ω–∞ JS-—Ç—è–∂–µ–ª—ã—Ö —Å–∞–π—Ç–∞—Ö
- –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–µ—Ç–µ–≤–æ–≥–æ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞
- Auto-waiting (–º–µ–Ω—å—à–µ –æ—à–∏–±–æ–∫)
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

**–ú–∏–Ω—É—Å—ã:**
- –ù–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (–Ω–æ –±—ã—Å—Ç—Ä–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è)

### –í–ê–†–ò–ê–ù–¢ 2: Selenium (–ü–†–û–í–ï–†–ï–ù–û)
**–ü–æ—á–µ–º—É:** –ù–∞–¥–µ–∂–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ, –º–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

**–ü–ª—é—Å—ã:**
- –°—Ç–∞–±–∏–ª—å–Ω—ã–π –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π
- –®–∏—Ä–æ–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –±—Ä–∞—É–∑–µ—Ä–æ–≤
- –ú–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ

**–ú–∏–Ω—É—Å—ã:**
- ~2x –º–µ–¥–ª–µ–Ω–Ω–µ–µ, —á–µ–º Playwright[88][89]
- –ë–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏
- –¢—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ waits

---

## üíª –ö–û–î: PLAYWRIGHT –†–ï–®–ï–ù–ò–ï (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

### –®–∞–≥ 1: –î–æ–±–∞–≤–∏—Ç—å Playwright –≤ requirements.txt

```
playwright==1.48.0
playwright-stealth==1.0.1
```

### –®–∞–≥ 2: –û–±–Ω–æ–≤–∏—Ç—å parsers/yandex_uslugi.py

```python
from parsers.base_parser import BaseParser
from typing import List, Dict, Optional
import re
import logging
from datetime import datetime
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

class YandexUslugiParser(BaseParser):
    def __init__(self):
        super().__init__(
            name="yandex_uslugi",
            base_url="https://uslugi.yandex.ru",
            timeout=30,
            delay=1.5  # –ú–µ–Ω–µ–µ –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã–π –Ω–∞ Playwright
        )
        self.categories_map = {
            "santehnika": "–°–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∞",
            "elektrika": "–≠–ª–µ–∫—Ç—Ä–∏–∫–∞",
            "uborka": "–£–±–æ—Ä–∫–∞",
            "remont": "–†–µ–º–æ–Ω—Ç",
            "master-na-chas": "–ú–∞—Å—Ç–µ—Ä –Ω–∞ —á–∞—Å"
        }
    
    async def parse(self) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Playwright —Å JavaScript –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"""
        orders = []
        
        try:
            async with async_playwright() as p:
                # –ó–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä
                browser = await p.chromium.launch(headless=True)
                
                for category_slug, category_name in self.categories_map.items():
                    self.logger.info(f"Parsing {category_name} with Playwright...")
                    
                    for city in ["moscow", "spb"]:
                        try:
                            # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É (context –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞)
                            page = await browser.new_page()
                            
                            # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å User-Agent (–Ø–Ω–¥–µ–∫—Å –º–æ–∂–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –±–æ—Ç–æ–≤)
                            await page.set_extra_http_headers({
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                            })
                            
                            # URL –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ –≥–æ—Ä–æ–¥–µ
                            url = f"{self.base_url}/{city}/category/{category_slug}"
                            
                            self.logger.debug(f"Navigating to {url}...")
                            
                            # –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –¥–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∫–∏
                            # waitUntil='networkidle' –∂–¥–µ—Ç –ø–æ–∫–∞ –≤—Å–µ network –∑–∞–ø—Ä–æ—Å—ã –∑–∞–≤–µ—Ä—à–∞—Ç—Å—è
                            await page.goto(url, wait_until='networkidle', timeout=30000)
                            
                            # ‚è≥ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ (JS –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
                            await page.wait_for_timeout(2000)
                            
                            # –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç—Ä–µ–Ω–¥–µ—Ä–µ–Ω–Ω—ã–π HTML
                            page_html = await page.content()
                            
                            # –ü–∞—Ä—Å–∏—Ç—å HTML —á–µ—Ä–µ–∑ BeautifulSoup
                            category_orders = await self._parse_category_page(
                                page_html, 
                                category_name, 
                                city
                            )
                            
                            orders.extend(category_orders)
                            
                            self.logger.info(f"Found {len(category_orders)} orders in {city}")
                            
                            await page.close()
                            
                            # Rate limiting
                            await self._rate_limit()
                        
                        except Exception as e:
                            self.logger.error(f"Error parsing {city}/{category_slug}: {e}")
                            if page:
                                await page.close()
                
                await browser.close()
        
        except Exception as e:
            self.logger.error(f"Playwright error: {e}")
        
        self.logger.info(f"Total orders parsed: {len(orders)}")
        return orders
    
    async def _parse_category_page(self, html: str, category: str, city: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏—Ç—å HTML –ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ JavaScript –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è"""
        orders = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ (—Ä–∞–∑–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ —Å–∞–π—Ç–∞)
        selectors = [
            'div[class*="Order"]',
            'div[class*="order"]',
            'article[class*="order"]',
            'div[data-testid*="order"]'
        ]
        
        cards = []
        for selector in selectors:
            cards = soup.select(selector)
            if cards:
                self.logger.debug(f"Found {len(cards)} cards with selector: {selector}")
                break
        
        if not cards:
            self.logger.warning(f"No order cards found for {city}/{category}")
            return orders
        
        for card in cards:
            try:
                order = self._parse_order(card)
                if order:
                    order['category'] = category
                    order['location'] = city
                    order['platform'] = 'yandex_uslugi'
                    orders.append(order)
            
            except Exception as e:
                self.logger.debug(f"Error parsing card: {e}")
        
        return orders
    
    def _parse_order(self, item) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–∫–∞–∑ –∏–∑ HTML"""
        try:
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–∞–π—Ç–∏ ID (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö)
            order_id = None
            
            # –í–∞—Ä–∏–∞–Ω—Ç 1: data –∞—Ç—Ä–∏–±—É—Ç
            for attr in ['data-id', 'data-order-id', 'data-testid']:
                if item.get(attr):
                    order_id = item.get(attr)
                    break
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –≤ href —Å—Å—ã–ª–∫–∏
            if not order_id:
                link = item.find('a', href=re.compile(r'/zakazy/|/order'))
                if link:
                    href = link.get('href', '')
                    match = re.search(r'(\d+)', href)
                    order_id = match.group(1) if match else None
            
            if not order_id:
                return None
            
            # –ü–æ–ª—É—á–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤)
            title = None
            for tag in ['h3', 'h2', 'a']:
                title_elem = item.find(tag)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    if title and len(title) > 3:
                        break
            
            # –ü–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ
            description = None
            for class_name in ['description', 'text', 'content', 'body']:
                desc_elem = item.find('p', class_=re.compile(f'.*{class_name}.*', re.I))
                if desc_elem:
                    description = desc_elem.get_text(strip=True)
                    break
            
            # –ü–æ–ª—É—á–∏—Ç—å –±—é–¥–∂–µ—Ç
            budget = None
            for class_name in ['price', 'budget', 'amount']:
                price_elem = item.find(re.compile('span|div'), class_=re.compile(f'.*{class_name}.*', re.I))
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    budget = self._parse_budget(price_text)
                    if budget:
                        break
            
            # –§–∏–ª—å—Ç—Ä —Å–ø–∞–º–∞
            if self._is_spam(title, description):
                self.logger.debug(f"Spam detected: {title}")
                return None
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            if not title or not description:
                return None
            
            return {
                'platform_order_id': str(order_id),
                'title': title[:500],
                'description': description[:2000],
                'budget': budget,
                'raw_data': str(item)[:1000]
            }
        
        except Exception as e:
            self.logger.error(f"Parse order error: {e}")
            return None
    
    def _parse_budget(self, budget_text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ—á—å –±—é–¥–∂–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not budget_text:
            return None
        
        # –£–¥–∞–ª–∏—Ç—å –≤—Å—ë –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ —Ç–æ—á–µ–∫
        numbers = re.findall(r'\d+', budget_text)
        
        if numbers:
            # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∏—Å–µ–ª (–¥–∏–∞–ø–∞–∑–æ–Ω) - –≤–µ—Ä–Ω—É—Ç—å —Å—Ä–µ–¥–Ω–µ–µ
            if len(numbers) > 1:
                return (int(numbers[0]) + int(numbers[1])) // 2
            return int(numbers[0])
        
        return None
    
    def _is_spam(self, title: str, description: str) -> bool:
        """–§–∏–ª—å—Ç—Ä —Å–ø–∞–º–∞"""
        if not title or not description:
            return True
        
        spam_keywords = [
            r'\b–∫—É–ø–∏\b', r'\b–ø—Ä–æ–¥–∞–π\b', r'\b—Å—Å—ã–ª–∫–∞\b', r'\b–∫–ª–∏–∫\b',
            r'\b(whatsapp|telegram|viber)\b', r'\bhttps?://'
        ]
        
        text = (title + ' ' + description).lower()
        
        for pattern in spam_keywords:
            if re.search(pattern, text):
                return True
        
        # –ú–∏–Ω–∏–º—É–º —Å–∏–º–≤–æ–ª–æ–≤ (–æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è - —Å–ø–∞–º)
        if len(description) < 20:
            return True
        
        return False
```

### –®–∞–≥ 3: –û–±–Ω–æ–≤–∏—Ç—å requirements.txt

```bash
# –î–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü requirements.txt:
echo "playwright==1.48.0" >> requirements.txt
echo "playwright-stealth==1.0.1" >> requirements.txt

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Playwright –±—Ä–∞—É–∑–µ—Ä—ã
docker-compose exec bot playwright install chromium
```

### –®–∞–≥ 4: –û–±–Ω–æ–≤–∏—Ç—å docker-compose.yml

```yaml
# –í —Å–µ—Ä–≤–∏—Å–µ bot –¥–æ–±–∞–≤–∏—Ç—å:
environment:
  - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
volumes:
  - ./ms-playwright:/ms-playwright  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –±—Ä–∞—É–∑–µ—Ä—ã –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞–º–∏
```

---

## üîÑ –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ê: SELENIUM (–ï—Å–ª–∏ Playwright –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)

### –®–∞–≥ 1: –û–±–Ω–æ–≤–∏—Ç—å requirements.txt

```
selenium==4.15.2
```

### –®–∞–≥ 2: –ü–∞—Ä—Å–µ—Ä —á–µ—Ä–µ–∑ Selenium

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import logging
import asyncio

class YandexUslugiSeleniumParser(BaseParser):
    def __init__(self):
        super().__init__(
            name="yandex_uslugi_selenium",
            base_url="https://uslugi.yandex.ru",
            timeout=30
        )
    
    async def parse(self) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Selenium"""
        orders = []
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Chrome
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)')
        
        driver = None
        try:
            # –ó–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä
            driver = webdriver.Chrome(options=options)
            
            for category_slug, category_name in self.categories_map.items():
                self.logger.info(f"Parsing {category_name} with Selenium...")
                
                for city in ["moscow", "spb"]:
                    try:
                        url = f"{self.base_url}/{city}/category/{category_slug}"
                        driver.get(url)
                        
                        # ‚è≥ –ñ–¥–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (—è–≤–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ)
                        wait = WebDriverWait(driver, 15)
                        
                        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–¥–æ–∂–¥–∞—Ç—å –ø–æ–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –∑–∞–∫–∞–∑–∞–º–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è
                        try:
                            wait.until(
                                EC.presence_of_all_elements_located((By.CLASS_NAME, "OrderCard"))
                            )
                        except:
                            self.logger.warning(f"Elements not found with selector OrderCard")
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                        await asyncio.sleep(2)
                        
                        # –ü–æ–ª—É—á–∏—Ç—å HTML –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è JavaScript
                        page_html = driver.page_source
                        
                        # –ü–∞—Ä—Å–∏—Ç—å —á–µ—Ä–µ–∑ BeautifulSoup
                        soup = BeautifulSoup(page_html, 'html.parser')
                        cards = soup.find_all('div', class_=re.compile(r'.*order.*', re.I))
                        
                        for card in cards:
                            order = self._parse_order(card)
                            if order:
                                order['category'] = category_name
                                order['location'] = city
                                order['platform'] = 'yandex_uslugi'
                                orders.append(order)
                        
                        self.logger.info(f"Found {len(orders)} orders")
                        
                        await asyncio.sleep(self.delay)
                    
                    except Exception as e:
                        self.logger.error(f"Selenium parse error: {e}")
        
        finally:
            if driver:
                driver.quit()
        
        return orders
```

---

## üéØ –°–†–ê–í–ù–ï–ù–ò–ï: Playwright vs Selenium

| –ö—Ä–∏—Ç–µ—Ä–∏–π | Playwright | Selenium |
|----------|-----------|----------|
| **–°–∫–æ—Ä–æ—Å—Ç—å** | 2.3x –±—ã—Å—Ç—Ä–µ–µ | –ë–∞–∑–æ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å |
| **–ü–∞–º—è—Ç—å** | 30% –º–µ–Ω—å—à–µ | –ë–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ |
| **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å** | Auto-wait (–ª—É—á—à–µ) | –¢—Ä–µ–±—É–µ—Ç —è–≤–Ω—ã–π wait |
| **JS-—Å–∞–π—Ç—ã** | –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω | –•–æ—Ä–æ—à–æ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ |
| **Network –ø–µ—Ä–µ—Ö–≤–∞—Ç** | –í—Å—Ç—Ä–æ–µ–Ω | –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø. –∫–æ–¥ |
| **–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º** | –í—Å—Ç—Ä–æ–µ–Ω | –¢—Ä–µ–±—É–µ—Ç Grid |
| **–ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è** | –ü–æ–ª–æ–≥–∞—è | –ö—Ä—É—Ç–∞—è |

**–í–µ—Ä–¥–∏–∫—Ç:** Playwright –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JS-—Ç—è–∂–µ–ª—ã—Ö —Å–∞–π—Ç–æ–≤ (–≤—Ä–æ–¥–µ –Ø–Ω–¥–µ–∫—Å.–£—Å–ª—É–≥)[88][89][91][92]

---

## üöÄ –î–ï–ü–õ–û–ô –ù–ê VPS (–¥–ª—è Playwright)

### –ù–∞ VPS —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:

```bash
# SSH –Ω–∞ VPS
ssh ubuntu@your-vps-ip

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Chrome –¥–ª—è headless –ø–∞—Ä—Å–∏–Ω–≥–∞
sudo apt-get update
sudo apt-get install -y \
    libatk1.0-0 \
    libatk-bridge2.0-0 \
    libc6 \
    libcairo2 \
    libcups2 \
    libdbus-1-3 \
    libexpat1 \
    libfontconfig1 \
    libgcc1 \
    libgconf-2-4 \
    libgdk-pixbuf2.0-0 \
    libglib2.0-0 \
    libgtk-3-0 \
    libpango-1.0-0 \
    libpango-cairo-1.0-0 \
    libstdc++6 \
    libx11-6 \
    libx11-xcb1 \
    libxcb1 \
    libxcursor1 \
    libxdamage1 \
    libxext6 \
    libxfixes3 \
    libxi6 \
    libxrandr2 \
    libxrender1 \
    libxss1 \
    libxtst6 \
    fonts-liberation \
    libnss3 \
    libopensc2

# –í docker-compose.yml –±—Ä–∞—É–∑–µ—Ä —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
```

---

## üîç –û–¢–õ–ê–î–ö–ê

### –ï—Å–ª–∏ Playwright –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç —ç–ª–µ–º–µ–Ω—Ç—ã:

```python
# 1. –£–≤–µ–ª–∏—á–∏—Ç—å –æ–∂–∏–¥–∞–Ω–∏–µ
await page.wait_for_timeout(5000)  # 5 —Å–µ–∫—É–Ω–¥

# 2. –î–æ–∂–¥–∞—Ç—å—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
await page.wait_for_selector('div.OrderCard', timeout=20000)

# 3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
await page.screenshot(path='debug.png')

# 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
html = await page.content()
with open('debug.html', 'w') as f:
    f.write(html)
```

### –ï—Å–ª–∏ Selenium –∑–∞–≤–∏—Å–∞–µ—Ç:

```python
# –£–≤–µ–ª–∏—á–∏—Ç—å timeout
driver = webdriver.Chrome()
driver.set_page_load_timeout(30)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —è–≤–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
wait = WebDriverWait(driver, 15)
element = wait.until(EC.presence_of_element_located((By.CLASS_NAME, "OrderCard")))
```

---

## üìä –¢–ï–°–¢

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–µ—Ä –ª–æ–∫–∞–ª—å–Ω–æ
docker-compose up --build

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
docker-compose logs -f bot | grep -i "yandex\|playwright"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ë–î
docker-compose exec postgres psql -U verticalai_user -d verticalai_db -c \
  "SELECT COUNT(*) FROM orders WHERE platform='yandex_uslugi';"
```

---

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑—É–π **Playwright** - —ç—Ç–æ –±—É–¥—É—â–µ–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JS-—Å–∞–π—Ç–æ–≤. 2.3x –±—ã—Å—Ç—Ä–µ–µ, –Ω–∞–¥–µ–∂–Ω–µ–µ, –º–µ–Ω—å—à–µ –∫–æ–¥–∞.[88][89][91][92]

–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –¥–∞–π –º–Ω–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏ –∏–ª–∏ HTML –∫–æ–¥ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –¥–æ–¥–µ–ª–∞–µ–º! üöÄ
