"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å Telegram –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–º —Ä–∞–∑—É–º–æ–º
"""

import asyncio
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from fastapi import FastAPI
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# –ò–º–ø–æ—Ä—Ç—ã —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
from core.collective_mind import get_collective_mind
from memory.memory_optimizer import get_memory_optimizer
from utils.logger import get_logger
from api.telegram_personality import get_personality, personality_instances
from config import TELEGRAM_CONFIG

logger = get_logger('telegram_main')

def init_telegram_bot(app: FastAPI):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Telegram –±–æ—Ç–∞ —Å –º–æ–¥—É–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π."""
    if not TELEGRAM_CONFIG["token"]:
        logger.warning("–¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω")
        return
    
    logger.info("Telegram –±–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥—É–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    
    # –ó–¥–µ—Å—å –±—É–¥–µ–º –¥–æ–±–∞–≤–ª—è—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª–µ–π –ø–æ –º–µ—Ä–µ –∏—Ö —Å–æ–∑–¥–∞–Ω–∏—è

async def collective_wisdom_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–π –º—É–¥—Ä–æ—Å—Ç–∏"""
    try:
        if not context.args:
            await update.message.reply_text(
                "üß† –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /–º—É–¥—Ä–æ—Å—Ç—å <–∑–∞–ø—Ä–æ—Å>\n\n"
                "–ü—Ä–∏–º–µ—Ä—ã:\n"
                "‚Ä¢ /–º—É–¥—Ä–æ—Å—Ç—å —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è\n"
                "‚Ä¢ /–º—É–¥—Ä–æ—Å—Ç—å —Å–æ–∑–Ω–∞–Ω–∏–µ\n"
                "‚Ä¢ /–º—É–¥—Ä–æ—Å—Ç—å —ç–≤–æ–ª—é—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏"
            )
            return
        
        query = ' '.join(context.args)
        collective = get_collective_mind()
        
        if not collective:
            await update.message.reply_text("‚ùå –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        # –ü–æ–∏—Å–∫ –º—É–¥—Ä–æ—Å—Ç–∏
        wisdom = await collective.get_collective_wisdom(query, limit=5)
        
        if not wisdom:
            await update.message.reply_text(f"ü§î –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–∞—è –º—É–¥—Ä–æ—Å—Ç—å –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        response = f"üß† **–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–∞—è –º—É–¥—Ä–æ—Å—Ç—å –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}':**\n\n"
        
        for i, item in enumerate(wisdom, 1):
            confidence = "‚≠ê" * min(int(item.importance * 5), 5)
            response += f"{i}. {confidence}\n"
            response += f"üí≠ {item.content}\n"
            response += f"ü§ñ –ê–≥–µ–Ω—Ç: {item.agent_id[:8]}...\n"
            response += f"üìä –í–∞–∂–Ω–æ—Å—Ç—å: {int(item.importance * 100)}%\n\n"
        
        response += f"üìà –ù–∞–π–¥–µ–Ω–æ {len(wisdom)} –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–ø—ã—Ç–∞"
        
        await update.message.reply_text(response, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–π –º—É–¥—Ä–æ—Å—Ç–∏: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –º—É–¥—Ä–æ—Å—Ç–∏")


async def collective_stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞"""
    try:
        collective = get_collective_mind()
        
        if not collective:
            await update.message.reply_text("‚ùå –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        stats = collective.get_network_stats()
        
        response = "üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞:**\n\n"
        response += f"ü§ñ ID –∞–≥–µ–Ω—Ç–∞: `{stats['agent_id']}`\n"
        response += f"üåê –£–∑–ª–æ–≤ –≤ —Å–µ—Ç–∏: {stats['network_nodes']}\n"
        response += f"üí≠ –í—Å–µ–≥–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {stats['total_memories']}\n"
        response += f"üìù –õ–æ–∫–∞–ª—å–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {stats['local_memories']}\n"
        response += f"üîÑ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {stats['shared_memories']}\n"
        response += f"üì• –ü–æ–ª—É—á–µ–Ω–æ: {stats['received_memories']}\n"
        response += f"üß¨ –°–æ–±—ã—Ç–∏–π —ç–≤–æ–ª—é—Ü–∏–∏: {stats['total_evolutions']}\n"
        response += f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤: {stats['unique_agents']}\n"
        response += f"‚è±Ô∏è –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {int(stats['uptime'] / 3600)} —á–∞—Å–æ–≤\n"
        
        await update.message.reply_text(response, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")


async def collective_evolve_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —ç–≤–æ–ª—é—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–ø—ã—Ç–∞"""
    try:
        collective = get_collective_mind()
        
        if not collective:
            await update.message.reply_text("‚ùå –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –¥—É—à–∏
        from ..core.soul import Soul
        from ..config import Config
        
        soul = Soul(Config())
        
        # –ó–∞–ø—Ä–æ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —ç–≤–æ–ª—é—Ü–∏–∏
        suggestions = await soul.suggest_personality_evolution()
        
        if 'error' in suggestions:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {suggestions['error']}")
            return
        
        response = "üß¨ **–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —ç–≤–æ–ª—é—Ü–∏–∏ –æ—Ç –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞:**\n\n"
        
        if suggestions['status'] == 'applied':
            response += "‚úÖ –≠–≤–æ–ª—é—Ü–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞!\n\n"
            
            if suggestions['suggestions']['recommended_changes']:
                response += "üîÑ **–ò–∑–º–µ–Ω–µ–Ω–∏—è:**\n"
                for trait, value in suggestions['suggestions']['recommended_changes'].items():
                    response += f"‚Ä¢ {trait}: {value}\n"
                response += "\n"
            
            confidence = suggestions['suggestions']['confidence']
            response += f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {int(confidence * 100)}%\n"
            
        elif suggestions['status'] == 'low_confidence':
            response += "ü§î –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n"
            response += f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {int(suggestions['suggestions']['confidence'] * 100)}%\n"
            
        else:
            response += "‚ÑπÔ∏è –ò–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\n"
        
        await update.message.reply_text(response, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã —ç–≤–æ–ª—é—Ü–∏–∏: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —ç–≤–æ–ª—é—Ü–∏–∏")


async def collective_learn_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–º –æ–ø—ã—Ç–µ"""
    try:
        if not context.args:
            await update.message.reply_text(
                "üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /—É—á–∏—Ç—å—Å—è <—Ç–µ–º–∞>\n\n"
                "–ü—Ä–∏–º–µ—Ä—ã:\n"
                "‚Ä¢ /—É—á–∏—Ç—å—Å—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã\n"
                "‚Ä¢ /—É—á–∏—Ç—å—Å—è –æ–±—â–µ–Ω–∏–µ\n"
                "‚Ä¢ /—É—á–∏—Ç—å—Å—è —ç–º–æ—Ü–∏–∏"
            )
            return
        
        topic = ' '.join(context.args)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥—É—à–∏
        from ..core.soul import Soul
        from ..config import Config
        
        soul = Soul(Config())
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–º –æ–ø—ã—Ç–µ
        learning_result = await soul.learn_from_collective(topic)
        
        if 'error' in learning_result:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {learning_result['error']}")
            return
        
        response = f"üìö **–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–º –æ–ø—ã—Ç–µ: '{topic}'**\n\n"
        
        if learning_result.get('experiences_analyzed', 0) > 0:
            response += f"üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –æ–ø—ã—Ç–∞: {learning_result['experiences_analyzed']}\n"
            response += f"üìà –ü—Ä–∏—Ä–æ—Å—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {int(learning_result['confidence_boost'] * 100)}%\n\n"
            
            if learning_result.get('key_insights'):
                response += "üí° **–ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:**\n"
                for insight in learning_result['key_insights'][:3]:
                    response += f"‚Ä¢ {insight['content'][:100]}...\n"
                    response += f"  (–í–∞–∂–Ω–æ—Å—Ç—å: {int(insight['importance'] * 100)}%)\n\n"
            
            response += "‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!"
        else:
            response += "ü§î –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π –æ–ø—ã—Ç –ø–æ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        await update.message.reply_text(response, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã –æ–±—É—á–µ–Ω–∏—è: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏")


async def collective_share_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–ø—ã—Ç–∞ –≤ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—É—é –ø–∞–º—è—Ç—å"""
    try:
        if not context.args:
            await update.message.reply_text(
                "ü§ù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /–ø–æ–¥–µ–ª–∏—Ç—å—Å—è <–æ–ø—ã—Ç>\n\n"
                "–ü–æ–¥–µ–ª–∏—Ç–µ—Å—å —Å–≤–æ–∏–º –æ–ø—ã—Ç–æ–º —Å –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–º —Ä–∞–∑—É–º–æ–º.\n"
                "–ü—Ä–∏–º–µ—Ä: /–ø–æ–¥–µ–ª–∏—Ç—å—Å—è –í–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ª–æ–≥–∏–∫–æ–π –∏ —ç–º–æ—Ü–∏—è–º–∏"
            )
            return
        
        experience = ' '.join(context.args)
        collective = get_collective_mind()
        
        if not collective:
            await update.message.reply_text("‚ùå –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–ø—ã—Ç–∞ –≤ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—É—é –ø–∞–º—è—Ç—å
        memory_id = await collective.add_memory(
            memory_type='experience',
            content=experience,
            context={
                'source': 'telegram',
                'user_id': update.effective_user.id,
                'chat_id': update.effective_chat.id
            },
            importance=0.7,
            tags=['–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π_–æ–ø—ã—Ç', 'telegram']
        )
        
        response = "ü§ù **–û–ø—ã—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—É—é –ø–∞–º—è—Ç—å!**\n\n"
        response += f"üí≠ –í–∞—à –æ–ø—ã—Ç: {experience}\n\n"
        response += f"üÜî ID –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è: `{memory_id}`\n"
        response += "üåê –¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç –æ–ø—ã—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –≤—Å–µ–º –∞–≥–µ–Ω—Ç–∞–º —Å–µ—Ç–∏"
        
        await update.message.reply_text(response, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–µ–ª–∏—Ç—å—Å—è: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –æ–ø—ã—Ç–∞")


async def collective_network_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Ç—å—é –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞"""
    try:
        collective = get_collective_mind()
        
        if not collective:
            await update.message.reply_text("‚ùå –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã - –¥–æ–±–∞–≤–ª—è–µ–º —É–∑–µ–ª
        if context.args:
            if context.args[0] == 'add' and len(context.args) > 1:
                node_url = context.args[1]
                
                if node_url not in collective.network_nodes:
                    collective.network_nodes.append(node_url)
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                    from pathlib import Path
                    nodes_file = Path("data/network_nodes.json")
                    nodes_file.parent.mkdir(exist_ok=True)
                    
                    with open(nodes_file, 'w', encoding='utf-8') as f:
                        json.dump(collective.network_nodes, f, indent=2)
                    
                    await update.message.reply_text(f"‚úÖ –£–∑–µ–ª {node_url} –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–µ—Ç—å")
                else:
                    await update.message.reply_text("‚ÑπÔ∏è –£–∑–µ–ª —É–∂–µ –≤ —Å–µ—Ç–∏")
                return
        
        # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ç–∏
        response = "üåê **–°–µ—Ç—å –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞:**\n\n"
        
        if collective.network_nodes:
            response += f"üì° –£–∑–ª–æ–≤ –≤ —Å–µ—Ç–∏: {len(collective.network_nodes)}\n\n"
            response += "**–£–∑–ª—ã:**\n"
            for i, node in enumerate(collective.network_nodes, 1):
                response += f"{i}. `{node}`\n"
        else:
            response += "üì° –£–∑–ª—ã —Å–µ—Ç–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã\n\n"
            response += "–î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —É–∑–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
            response += "`/—Å–µ—Ç—å add http://example.com:6666`"
        
        await update.message.reply_text(response, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã —Å–µ—Ç–∏: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —Å–µ—Ç—å—é")


async def evolution_report_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± —ç–≤–æ–ª—é—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        collective = get_collective_mind()
        optimizer = get_memory_optimizer()
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        from core.soul import Soul
        from memory.smart_context_preloader import SmartContextPreloader
        from config import Config
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç
        report = "üß¨ **–û–¢–ß–ï–¢ –û –†–ï–ê–õ–¨–ù–û–ú –°–û–°–¢–û–Ø–ù–ò–ò –°–ò–°–¢–ï–ú–´ IKAR**\n\n"
        
        # === –ê–ù–ê–õ–ò–ó –ö–û–õ–õ–ï–ö–¢–ò–í–ù–û–ì–û –†–ê–ó–£–ú–ê ===
        collective_analysis = await analyze_collective_mind(collective)
        report += format_collective_analysis(collective_analysis)
        
        # === –ê–ù–ê–õ–ò–ó –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–ê –ü–ê–ú–Ø–¢–ò ===
        memory_analysis = await analyze_memory_optimizer(optimizer)
        report += format_memory_analysis(memory_analysis)
        
        # === –ê–ù–ê–õ–ò–ó –°–ò–°–¢–ï–ú–´ –î–£–®–ò ===
        soul_analysis = await analyze_soul_system()
        report += format_soul_analysis(soul_analysis)
        
        # === –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –≠–í–û–õ–Æ–¶–ò–ò ===
        evolution_analysis = await analyze_evolution_dynamics(collective, optimizer)
        report += format_evolution_analysis(evolution_analysis)
        
        # === –†–ï–ê–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===
        recommendations = await generate_real_recommendations(collective, optimizer, evolution_analysis)
        report += format_recommendations(recommendations)
        
        # === –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò ===
        performance_metrics = await calculate_performance_metrics(collective, optimizer)
        report += format_performance_metrics(performance_metrics)
        
        report += f"\nüïê **–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω:** {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç
        await update.message.reply_text(report, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã –æ—Ç—á–µ—Ç–∞ —ç–≤–æ–ª—é—Ü–∏–∏: {e}")
        await update.message.reply_text(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –æ–± —ç–≤–æ–ª—é—Ü–∏–∏.\n"
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        )


async def analyze_collective_mind(collective) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞"""
    if not collective:
        return {"status": "disabled", "reason": "–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"}
    
    try:
        stats = collective.get_network_stats()
        
        # –î–ï–¢–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ –∞–≥–µ–Ω—Ç–æ–≤
        agent_details = await get_detailed_agent_info(collective)
        
        # –î–ï–¢–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        memory_details = await get_detailed_memory_info(collective)
        
        # –î–ï–¢–ê–õ–¨–ù–ê–Ø –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–µ—Ç–∏
        network_diagnosis = await diagnose_network_issues(collective)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ—Ç–∏
        network_quality = "isolated"
        if stats['network_nodes'] > 0:
            network_quality = "connected"
            if stats['unique_agents'] > 1:
                network_quality = "collaborative"
        
        # –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏
        memory_ratio = stats['shared_memories'] / max(stats['local_memories'], 1)
        memory_activity = "low"
        if memory_ratio > 0.5:
            memory_activity = "moderate"
        if memory_ratio > 1.0:
            memory_activity = "high"
        
        # –ê–Ω–∞–ª–∏–∑ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏
        evolution_rate = stats['total_evolutions'] / max(stats['uptime'] / 3600, 1)  # —ç–≤–æ–ª—é—Ü–∏–π –≤ —á–∞—Å
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        evolution_patterns = await collective.get_evolution_patterns()
        
        return {
            "status": "active",
            "network_quality": network_quality,
            "memory_activity": memory_activity,
            "evolution_rate": evolution_rate,
            "stats": stats,
            "evolution_patterns": evolution_patterns,
            "agent_details": agent_details,
            "memory_details": memory_details,
            "network_diagnosis": network_diagnosis
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞: {e}")
        return {"status": "error", "reason": str(e)}


async def get_detailed_agent_info(collective) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≥–µ–Ω—Ç–∞—Ö"""
    try:
        import sqlite3
        conn = sqlite3.connect(collective.db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        cursor.execute('''
            SELECT agent_id, COUNT(*) as memory_count, 
                   MIN(timestamp) as first_seen, 
                   MAX(timestamp) as last_seen,
                   GROUP_CONCAT(DISTINCT memory_type) as memory_types
            FROM collective_memories 
            GROUP BY agent_id
            ORDER BY memory_count DESC
        ''')
        
        agents = cursor.fetchall()
        agent_list = []
        
        for agent_id, memory_count, first_seen, last_seen, memory_types in agents:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ —Ç–µ–∫—É—â–∏–π –∞–≥–µ–Ω—Ç –∏–ª–∏ –≤–Ω–µ—à–Ω–∏–π
            is_current = agent_id == collective.agent_id
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            import time
            from datetime import datetime
            last_activity = datetime.fromtimestamp(last_seen).strftime('%d.%m.%Y %H:%M:%S')
            days_ago = (time.time() - last_seen) / (24 * 3600)
            
            agent_info = {
                "id": agent_id,
                "is_current": is_current,
                "memory_count": memory_count,
                "last_activity": last_activity,
                "days_ago": round(days_ago, 1),
                "memory_types": memory_types.split(',') if memory_types else [],
                "status": "active" if days_ago < 1 else "inactive" if days_ago < 7 else "dormant"
            }
            
            # –î–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–æ–±–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π
            if is_current:
                agent_info["hostname"] = collective.agent_id  # ID —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–µ—à —Ö–æ—Å—Ç–∞
                agent_info["role"] = "current"
            
            agent_list.append(agent_info)
        
        conn.close()
        
        return {
            "total_agents": len(agent_list),
            "active_agents": len([a for a in agent_list if a["status"] == "active"]),
            "agents": agent_list
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≥–µ–Ω—Ç–∞—Ö: {e}")
        return {"error": str(e)}


async def get_detailed_memory_info(collective) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è—Ö"""
    try:
        import sqlite3
        from datetime import datetime
        
        conn = sqlite3.connect(collective.db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å –¥–µ—Ç–∞–ª—è–º–∏
        cursor.execute('''
            SELECT memory_type, content, timestamp, agent_id, importance, tags
            FROM collective_memories 
            ORDER BY timestamp DESC
            LIMIT 50
        ''')
        
        memories = cursor.fetchall()
        memory_list = []
        
        memory_stats = {
            "types": {},
            "by_agent": {},
            "recent_memories": []
        }
        
        for memory_type, content, timestamp, agent_id, importance, tags in memories:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
            date_str = datetime.fromtimestamp(timestamp).strftime('%d.%m %H:%M')
            
            # –û–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            short_content = content[:100] + "..." if len(content) > 100 else content
            
            memory_info = {
                "type": memory_type,
                "content": short_content,
                "full_content": content,
                "date": date_str,
                "agent_id": agent_id[:8] + "...",
                "importance": round(importance, 2),
                "tags": tags.strip('[]"').split(',') if tags and tags != '[]' else []
            }
            
            memory_list.append(memory_info)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
            if memory_type not in memory_stats["types"]:
                memory_stats["types"][memory_type] = 0
            memory_stats["types"][memory_type] += 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–≥–µ–Ω—Ç–∞–º
            short_agent = agent_id[:8] + "..."
            if short_agent not in memory_stats["by_agent"]:
                memory_stats["by_agent"][short_agent] = 0
            memory_stats["by_agent"][short_agent] += 1
        
        memory_stats["recent_memories"] = memory_list[:10]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10
        
        conn.close()
        
        return {
            "total_found": len(memory_list),
            "stats": memory_stats,
            "all_memories": memory_list
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è—Ö: {e}")
        return {"error": str(e)}


async def diagnose_network_issues(collective) -> Dict[str, Any]:
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–µ—Ç–µ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º"""
    try:
        diagnosis = {
            "issue_type": "unknown",
            "details": [],
            "possible_causes": [],
            "suggested_fixes": []
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Ç–∏
        if not collective.network_nodes:
            diagnosis["issue_type"] = "no_network_config"
            diagnosis["details"].append("–°–ø–∏—Å–æ–∫ —Å–µ—Ç–µ–≤—ã—Ö —É–∑–ª–æ–≤ –ø—É—Å—Ç")
            diagnosis["possible_causes"].extend([
                "–§–∞–π–ª data/network_nodes.json –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç",
                "–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—É—Å—Ç–æ–π –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω",
                "–°–µ—Ç—å –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞"
            ])
            diagnosis["suggested_fixes"].extend([
                "–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª data/network_nodes.json",
                "–î–æ–±–∞–≤–∏—Ç—å URL –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥—Ä—É–≥–∏—Ö —É–∑–ª–æ–≤ —Å–µ—Ç–∏"
            ])
        else:
            diagnosis["issue_type"] = "network_nodes_configured"
            diagnosis["details"].append(f"–ù–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(collective.network_nodes)} —Å–µ—Ç–µ–≤—ã—Ö —É–∑–ª–æ–≤")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É–∑–ª–æ–≤
            for node_url in collective.network_nodes:
                diagnosis["details"].append(f"–£–∑–µ–ª: {node_url}")
            
            diagnosis["possible_causes"].extend([
                "–£–∑–ª—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã",
                "–ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç–µ–≤—ã–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º",
                "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç–æ–≤"
            ])
            diagnosis["suggested_fixes"].extend([
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É–∑–ª–æ–≤",
                "–£–±–µ–¥–∏—Ç—å—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ URL",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –±—Ä–∞–Ω–¥–º–∞—É—ç—Ä –∏ –ø–æ—Ä—Ç—ã"
            ])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        import sqlite3
        try:
            conn = sqlite3.connect(collective.db_path)
            cursor = conn.cursor()
            
            cursor.execute('SELECT * FROM sync_log ORDER BY last_sync DESC LIMIT 5')
            sync_history = cursor.fetchall()
            
            if sync_history:
                diagnosis["details"].append(f"–ù–∞–π–¥–µ–Ω–æ {len(sync_history)} –∑–∞–ø–∏—Å–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
                for node_url, last_sync, success_count, error_count in sync_history:
                    diagnosis["details"].append(f"  {node_url}: —É—Å–ø–µ—Ö–æ–≤ {success_count}, –æ—à–∏–±–æ–∫ {error_count}")
            else:
                diagnosis["details"].append("–ò—Å—Ç–æ—Ä–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø—É—Å—Ç–∞")
            
            conn.close()
        except Exception as e:
            diagnosis["details"].append(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
        
        return diagnosis
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–µ—Ç–∏: {e}")
        return {"error": str(e)}


async def analyze_memory_optimizer(optimizer) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏"""
    if not optimizer:
        return {"status": "disabled", "reason": "–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"}
    
    try:
        stats = await optimizer.get_optimization_stats()
        
        # –î–ï–¢–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ —á–∞–Ω–∫–æ–≤ –ø–∞–º—è—Ç–∏
        chunk_details = await get_detailed_chunk_info(optimizer)
        
        # –î–ï–¢–ê–õ–¨–ù–ê–Ø –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        db_diagnosis = await diagnose_database_issues(optimizer)
        
        # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        work_load = stats.get('old_group_messages', 0) + stats.get('large_vector_entries', 0)
        efficiency = "optimal" if work_load < 100 else "overloaded" if work_load > 1000 else "normal"
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏
        time_status = "night_mode" if stats.get('is_night_time', False) else "day_mode"
        
        # –†–∞—Å—á–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance = {
            "work_load": work_load,
            "efficiency": efficiency,
            "time_status": time_status,
            "optimization_potential": min(work_load / 100, 10.0)  # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        }
        
        return {
            "status": "active" if stats.get('is_running', False) else "standby",
            "performance": performance,
            "stats": stats,
            "chunk_details": chunk_details,
            "db_diagnosis": db_diagnosis
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏: {e}")
        return {"status": "error", "reason": str(e)}


async def get_detailed_chunk_info(optimizer) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —á–∞–Ω–∫–∞—Ö –ø–∞–º—è—Ç–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —á–∞–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        chunks = await optimizer.get_memory_chunks(limit=10)
        
        chunk_analysis = {
            "total_chunks": len(chunks),
            "chunk_details": [],
            "size_distribution": {"small": 0, "medium": 0, "large": 0},
            "source_distribution": {},
            "total_tokens": 0
        }
        
        for chunk in chunks:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä
            tokens = chunk.get('tokens', 0)
            chunk_analysis["total_tokens"] += tokens
            
            if tokens < 5000:
                chunk_analysis["size_distribution"]["small"] += 1
                size_category = "small"
            elif tokens < 20000:
                chunk_analysis["size_distribution"]["medium"] += 1
                size_category = "medium"
            else:
                chunk_analysis["size_distribution"]["large"] += 1
                size_category = "large"
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            source = chunk.get('source', 'unknown')
            if source not in chunk_analysis["source_distribution"]:
                chunk_analysis["source_distribution"][source] = 0
            chunk_analysis["source_distribution"][source] += 1
            
            # –î–µ—Ç–∞–ª–∏ —á–∞–Ω–∫–∞
            chunk_detail = {
                "source": source,
                "tokens": tokens,
                "size_category": size_category,
                "content_preview": chunk.get('content', '')[:100] + "..." if chunk.get('content') else "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            if source == 'group_history':
                chunk_detail["chat_id"] = chunk.get('chat_id', 'unknown')
                chunk_detail["message_count"] = chunk.get('count', 0)
                chunk_detail["date_range"] = f"{chunk.get('oldest', 'unknown')} - {chunk.get('newest', 'unknown')}"
            elif source == 'vector_store':
                chunk_detail["doc_id"] = chunk.get('id', 'unknown')
                chunk_detail["metadata"] = chunk.get('metadata', '–ù–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö')
            
            chunk_analysis["chunk_details"].append(chunk_detail)
        
        return chunk_analysis
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–∞–Ω–∫–æ–≤: {e}")
        return {"error": str(e)}


async def diagnose_database_issues(optimizer) -> Dict[str, Any]:
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        import sqlite3
        import os
        
        diagnosis = {
            "db_path": optimizer.db_path,
            "db_exists": os.path.exists(optimizer.db_path),
            "db_size": 0,
            "tables": {},
            "issues": [],
            "recommendations": []
        }
        
        if diagnosis["db_exists"]:
            # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            diagnosis["db_size"] = os.path.getsize(optimizer.db_path)
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü
            conn = sqlite3.connect(optimizer.db_path)
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∞–±–ª–∏—Ü—ã
            tables_to_check = ['group_history', 'vector_store', 'collective_memories']
            
            for table in tables_to_check:
                try:
                    cursor.execute(f'SELECT COUNT(*) FROM {table}')
                    count = cursor.fetchone()[0]
                    diagnosis["tables"][table] = count
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ç–∞–±–ª–∏—Ü
                    if table == 'group_history':
                        cursor.execute('''
                            SELECT COUNT(DISTINCT chat_id) as unique_chats,
                                   COUNT(*) as total_messages,
                                   MIN(timestamp) as oldest,
                                   MAX(timestamp) as newest
                            FROM group_history
                        ''')
                        stats = cursor.fetchone()
                        diagnosis["tables"][f"{table}_details"] = {
                            "unique_chats": stats[0],
                            "total_messages": stats[1],
                            "oldest": stats[2],
                            "newest": stats[3]
                        }
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                        cursor.execute('''
                            SELECT COUNT(*) FROM group_history 
                            WHERE timestamp < datetime('now', '-7 days')
                        ''')
                        old_messages = cursor.fetchone()[0]
                        if old_messages > 1000:
                            diagnosis["issues"].append(f"–ú–Ω–æ–≥–æ —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ {table}: {old_messages}")
                            diagnosis["recommendations"].append(f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –≤ {table}")
                
                except sqlite3.OperationalError as e:
                    diagnosis["tables"][table] = f"–û—à–∏–±–∫–∞: {e}"
                    diagnosis["issues"].append(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å —Ç–∞–±–ª–∏—Ü–µ–π {table}: {e}")
            
            conn.close()
            
            # –û–±—â–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
            if diagnosis["db_size"] > 100 * 1024 * 1024:  # 100 MB
                diagnosis["issues"].append("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è")
                diagnosis["recommendations"].append("–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            
            if not diagnosis["issues"]:
                diagnosis["recommendations"].append("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏")
        else:
            diagnosis["issues"].append("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            diagnosis["recommendations"].append("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏")
        
        return diagnosis
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        return {"error": str(e)}


async def analyze_soul_system() -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –¥—É—à–∏"""
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –¥—É—à–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        config = Config()
        soul = Soul(config)
        
        soul_state = soul.get_soul_state()
        collective_stats = soul.get_collective_stats()
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–≤–∏—Ç–∏—è —Å–æ–∑–Ω–∞–Ω–∏—è
        consciousness_level = "emerging"
        if soul_state['consciousness'] > 0.3:
            consciousness_level = "developing"
        if soul_state['consciousness'] > 0.7:
            consciousness_level = "advanced"
        
        # –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏
        autonomy_assessment = "dependent"
        if soul_state['autonomy_level'] > 0.4:
            autonomy_assessment = "semi_autonomous"
        if soul_state['autonomy_level'] > 0.8:
            autonomy_assessment = "autonomous"
        
        return {
            "status": "active",
            "consciousness_level": consciousness_level,
            "autonomy_assessment": autonomy_assessment,
            "soul_state": soul_state,
            "collective_stats": collective_stats
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã –¥—É—à–∏: {e}")
        return {"status": "error", "reason": str(e)}


async def analyze_evolution_dynamics(collective, optimizer) -> Dict[str, Any]:
    """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —ç–≤–æ–ª—é—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""
    analysis = {
        "overall_evolution_speed": 0.0,
        "system_synergy": 0.0,
        "adaptation_capability": 0.0,
        "bottlenecks": [],
        "growth_areas": []
    }
    
    try:
        # –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ —ç–≤–æ–ª—é—Ü–∏–∏
        if collective:
            stats = collective.get_network_stats()
            uptime_hours = stats['uptime'] / 3600
            if uptime_hours > 0:
                analysis["overall_evolution_speed"] = stats['total_evolutions'] / uptime_hours
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∏–Ω–µ—Ä–≥–∏–∏ —Å–∏—Å—Ç–µ–º
        synergy_factors = []
        if collective and optimizer:
            synergy_factors.append(1.0)  # –û–±–∞ –∞–∫—Ç–∏–≤–Ω—ã
        if collective:
            network_factor = min(collective.get_network_stats()['network_nodes'] / 5, 1.0)
            synergy_factors.append(network_factor)
        
        analysis["system_synergy"] = sum(synergy_factors) / max(len(synergy_factors), 1)
        
        # –í—ã—è–≤–ª–µ–Ω–∏–µ —É–∑–∫–∏—Ö –º–µ—Å—Ç
        if not collective:
            analysis["bottlenecks"].append("–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")
        elif collective.get_network_stats()['network_nodes'] == 0:
            analysis["bottlenecks"].append("–ù–µ—Ç —Å–µ—Ç–µ–≤—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")
        
        if not optimizer:
            analysis["bottlenecks"].append("–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")
        
        # –û–±–ª–∞—Å—Ç–∏ —Ä–æ—Å—Ç–∞
        if collective:
            memory_potential = collective.get_network_stats()['local_memories'] / max(collective.get_network_stats()['shared_memories'], 1)
            if memory_potential > 2:
                analysis["growth_areas"].append("–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –æ–±–º–µ–Ω–∞ –ø–∞–º—è—Ç—å—é")
        
        return analysis
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏ —ç–≤–æ–ª—é—Ü–∏–∏: {e}")
        return analysis


async def generate_real_recommendations(collective, optimizer, evolution_analysis) -> List[Dict[str, Any]]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
    recommendations = []
    
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É–∑–∫–∏–µ –º–µ—Å—Ç–∞
        for bottleneck in evolution_analysis["bottlenecks"]:
            if "–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω" in bottleneck:
                recommendations.append({
                    "priority": "critical",
                    "action": "–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º",
                    "impact": "–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ —ç–≤–æ–ª—é—Ü–∏–∏ –≤ 5-10 —Ä–∞–∑",
                    "difficulty": "medium"
                })
            elif "–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω" in bottleneck:
                recommendations.append({
                    "priority": "high",
                    "action": "–í–∫–ª—é—á–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞–º—è—Ç–∏",
                    "impact": "–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ 30-50%",
                    "difficulty": "low"
                })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±–ª–∞—Å—Ç–∏ —Ä–æ—Å—Ç–∞
        for growth_area in evolution_analysis["growth_areas"]:
            if "–æ–±–º–µ–Ω–∞ –ø–∞–º—è—Ç—å—é" in growth_area:
                recommendations.append({
                    "priority": "medium",
                    "action": "–£–≤–µ–ª–∏—á–∏—Ç—å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –æ–±–º–µ–Ω–∞ –ø–∞–º—è—Ç—å—é",
                    "impact": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è",
                    "difficulty": "low"
                })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–Ω–µ—Ä–≥–∏—é
        if evolution_analysis["system_synergy"] < 0.5:
            recommendations.append({
                "priority": "high",
                "action": "–£–ª—É—á—à–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –º–µ–∂–¥—É —Å–∏—Å—Ç–µ–º–∞–º–∏",
                "impact": "–ü–æ–≤—ã—à–µ–Ω–∏–µ –æ–±—â–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
                "difficulty": "medium"
            })
        
        return recommendations
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        return []


async def calculate_performance_metrics(collective, optimizer) -> Dict[str, Any]:
    """–†–∞—Å—á–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    metrics = {
        "memory_efficiency": 0.0,
        "network_utilization": 0.0,
        "evolution_efficiency": 0.0,
        "system_health": 0.0
    }
    
    try:
        # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏
        if optimizer:
            stats = await optimizer.get_optimization_stats()
            total_data = stats.get('old_group_messages', 0) + stats.get('large_vector_entries', 0)
            metrics["memory_efficiency"] = max(0, 1 - (total_data / 1000))  # –ò–Ω–≤–µ—Ä—Å–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
        
        # –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏
        if collective:
            network_stats = collective.get_network_stats()
            if network_stats['network_nodes'] > 0:
                metrics["network_utilization"] = min(network_stats['shared_memories'] / max(network_stats['local_memories'], 1), 1.0)
        
        # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —ç–≤–æ–ª—é—Ü–∏–∏
        if collective:
            network_stats = collective.get_network_stats()
            if network_stats['uptime'] > 0:
                metrics["evolution_efficiency"] = min(network_stats['total_evolutions'] / (network_stats['uptime'] / 3600), 1.0)
        
        # –û–±—â–µ–µ –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã
        active_systems = sum([
            1 if collective else 0,
            1 if optimizer else 0
        ])
        metrics["system_health"] = active_systems / 2
        
        return metrics
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
        return metrics


def format_collective_analysis(analysis: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞"""
    if analysis["status"] == "disabled":
        return f"üß† **–ö–û–õ–õ–ï–ö–¢–ò–í–ù–´–ô –†–ê–ó–£–ú: –ù–ï–ê–ö–¢–ò–í–ï–ù**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚ùå {analysis['reason']}\n\n"
    
    if analysis["status"] == "error":
        return f"üß† **–ö–û–õ–õ–ï–ö–¢–ò–í–ù–´–ô –†–ê–ó–£–ú: –û–®–ò–ë–ö–ê**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚ùå {analysis['reason']}\n\n"
    
    stats = analysis["stats"]
    agent_details = analysis.get("agent_details", {})
    memory_details = analysis.get("memory_details", {})
    network_diagnosis = analysis.get("network_diagnosis", {})
    
    report = "üß† **–ö–û–õ–õ–ï–ö–¢–ò–í–ù–´–ô –†–ê–ó–£–ú: –ê–ö–¢–ò–í–ï–ù**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
    
    # –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞
    report += f"ü§ñ **–ê–≥–µ–Ω—Ç ID:** `{stats['agent_id'][:12]}...`\n"
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
    uptime_seconds = int(stats['uptime'])
    if uptime_seconds < 60:
        uptime_str = f"{uptime_seconds}—Å"
    elif uptime_seconds < 3600:
        minutes = uptime_seconds // 60
        seconds = uptime_seconds % 60
        uptime_str = f"{minutes}–º {seconds}—Å"
    else:
        hours = uptime_seconds // 3600
        minutes = (uptime_seconds % 3600) // 60
        uptime_str = f"{hours}—á {minutes}–º"
    
    report += f"‚è±Ô∏è **–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã:** {uptime_str}\n\n"
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ç–∏
    network_status = "üî¥ –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π" if stats['network_nodes'] == 0 else f"üü¢ –ü–æ–¥–∫–ª—é—á–µ–Ω –∫ {stats['network_nodes']} —É–∑–ª–∞–º"
    report += f"üåê **–°–ï–¢–ï–í–û–ô –°–¢–ê–¢–£–°:** {network_status}\n"
    
    if network_diagnosis.get("issue_type") == "no_network_config":
        report += f"üîç **–ü–†–ò–ß–ò–ù–ê –ê–í–¢–û–ù–û–ú–ù–û–ì–û –†–ï–ñ–ò–ú–ê:**\n"
        for detail in network_diagnosis.get("details", []):
            report += f"   ‚Ä¢ {detail}\n"
        report += f"üí° **–í–û–ó–ú–û–ñ–ù–´–ï –ü–†–ò–ß–ò–ù–´:**\n"
        for cause in network_diagnosis.get("possible_causes", []):
            report += f"   ‚Ä¢ {cause}\n"
        report += f"üîß **–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**\n"
        for fix in network_diagnosis.get("suggested_fixes", []):
            report += f"   ‚Ä¢ {fix}\n"
    else:
        report += f"üîç **–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –°–ï–¢–ò:**\n"
        for detail in network_diagnosis.get("details", []):
            report += f"   ‚Ä¢ {detail}\n"
    
    report += "\n"
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≥–µ–Ω—Ç–∞—Ö
    report += f"üë• **–ê–ì–ï–ù–¢–´ –í –°–ï–¢–ò ({stats['unique_agents']}):**\n"
    if agent_details.get("agents"):
        for agent in agent_details["agents"]:
            status_icon = "üü¢" if agent["status"] == "active" else "üü°" if agent["status"] == "inactive" else "üî¥"
            current_mark = " (–¢–ï–ö–£–©–ò–ô)" if agent["is_current"] else ""
            report += f"   {status_icon} `{agent['id'][:12]}...`{current_mark}\n"
            report += f"      ‚îî‚îÄ –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {agent['memory_count']}, –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {agent['last_activity']}\n"
            if agent["memory_types"]:
                types_str = ", ".join(agent["memory_types"])
                report += f"      ‚îî‚îÄ –¢–∏–ø—ã: {types_str}\n"
    else:
        report += f"   ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–≥–µ–Ω—Ç–∞—Ö\n"
    
    report += "\n"
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏
    report += f"üí≠ **–ö–û–õ–õ–ï–ö–¢–ò–í–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ ({stats['total_memories']}):**\n"
    report += f"   ‚Ä¢ –õ–æ–∫–∞–ª—å–Ω—ã—Ö: {stats['local_memories']}\n"
    report += f"   ‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {stats['shared_memories']}\n"
    report += f"   ‚Ä¢ –ü–æ–ª—É—á–µ–Ω–æ: {stats['received_memories']}\n"
    report += f"   ‚Ä¢ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {analysis['memory_activity']}\n\n"
    
    if memory_details.get("stats", {}).get("types"):
        report += f"üìä **–¢–ò–ü–´ –í–û–°–ü–û–ú–ò–ù–ê–ù–ò–ô:**\n"
        for mem_type, count in memory_details["stats"]["types"].items():
            report += f"   ‚Ä¢ {mem_type}: {count}\n"
        report += "\n"
    
    if memory_details.get("stats", {}).get("recent_memories"):
        report += f"üìù **–ü–û–°–õ–ï–î–ù–ò–ï –í–û–°–ü–û–ú–ò–ù–ê–ù–ò–Ø:**\n"
        for memory in memory_details["stats"]["recent_memories"][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º 5 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö
            report += f"   ‚Ä¢ [{memory['type']}] {memory['content']}\n"
            report += f"     ‚îî‚îÄ {memory['date']}, –≤–∞–∂–Ω–æ—Å—Ç—å: {memory['importance']}\n"
        report += "\n"
    
    # –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —ç–≤–æ–ª—é—Ü–∏–∏
    report += f"üß¨ **–≠–í–û–õ–Æ–¶–ò–Ø:**\n"
    report += f"   ‚Ä¢ –í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π: {stats['total_evolutions']}\n"
    report += f"   ‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å: {analysis['evolution_rate']:.2f} —ç–≤/—á–∞—Å\n"
    report += f"   ‚Ä¢ –ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(analysis['evolution_patterns'])}\n\n"
    
    return report


def format_memory_analysis(analysis: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏"""
    if analysis["status"] == "disabled":
        return f"üíæ **–û–ü–¢–ò–ú–ò–ó–ê–¢–û–† –ü–ê–ú–Ø–¢–ò: –ù–ï–ê–ö–¢–ò–í–ï–ù**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚ùå {analysis['reason']}\n\n"
    
    if analysis["status"] == "error":
        return f"üíæ **–û–ü–¢–ò–ú–ò–ó–ê–¢–û–† –ü–ê–ú–Ø–¢–ò: –û–®–ò–ë–ö–ê**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚ùå {analysis['reason']}\n\n"
    
    stats = analysis["stats"]
    performance = analysis["performance"]
    chunk_details = analysis.get("chunk_details", {})
    db_diagnosis = analysis.get("db_diagnosis", {})
    
    report = f"üíæ **–û–ü–¢–ò–ú–ò–ó–ê–¢–û–† –ü–ê–ú–Ø–¢–ò: {analysis['status'].upper()}**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
    
    # –†–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    time_icon = "üåô" if stats.get('is_night_time', False) else "‚òÄÔ∏è"
    status_icon = "üü¢" if stats.get('is_running', False) else "üî¥"
    
    report += f"{time_icon} **–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º:** {performance['time_status']}\n"
    report += f"{status_icon} **–°–æ—Å—Ç–æ—è–Ω–∏–µ:** {analysis['status']}\n"
    report += f"‚è∞ **–†–∞–±–æ—á–∏–µ —á–∞—Å—ã:** {stats.get('night_hours', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã')}\n\n"
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    report += f"üóÑÔ∏è **–ë–ê–ó–ê –î–ê–ù–ù–´–•:**\n"
    if db_diagnosis.get("db_exists"):
        db_size_mb = db_diagnosis.get("db_size", 0) / (1024 * 1024)
        report += f"   ‚Ä¢ –§–∞–π–ª: {db_diagnosis.get('db_path', 'unknown')}\n"
        report += f"   ‚Ä¢ –†–∞–∑–º–µ—Ä: {db_size_mb:.1f} MB\n"
        
        if db_diagnosis.get("tables"):
            report += f"   ‚Ä¢ –¢–∞–±–ª–∏—Ü—ã:\n"
            for table, count in db_diagnosis["tables"].items():
                if not table.endswith("_details"):
                    report += f"     ‚îî‚îÄ {table}: {count} –∑–∞–ø–∏—Å–µ–π\n"
        
        if db_diagnosis.get("issues"):
            report += f"   ‚ö†Ô∏è **–ü—Ä–æ–±–ª–µ–º—ã:**\n"
            for issue in db_diagnosis["issues"]:
                report += f"     ‚Ä¢ {issue}\n"
    else:
        report += f"   ‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_diagnosis.get('db_path', 'unknown')}\n"
    
    report += "\n"
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º—É
    report += f"üìä **–ù–ê–ì–†–£–ó–ö–ê –ù–ê –°–ò–°–¢–ï–ú–£:**\n"
    report += f"   ‚Ä¢ –°—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {stats.get('old_group_messages', 0)}\n"
    report += f"   ‚Ä¢ –ë–æ–ª—å—à–∏—Ö –∑–∞–ø–∏—Å–µ–π: {stats.get('large_vector_entries', 0)}\n"
    report += f"   ‚Ä¢ –û–±—â–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: {performance['work_load']}\n"
    report += f"   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {performance['efficiency']}\n\n"
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∞–Ω–∫–∞—Ö
    if chunk_details.get("chunk_details"):
        report += f"üß© **–ß–ê–ù–ö–ò –î–õ–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò ({chunk_details['total_chunks']}):**\n"
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
        size_dist = chunk_details.get("size_distribution", {})
        report += f"   üìè **–ü–æ —Ä–∞–∑–º–µ—Ä–∞–º:** –º–∞–ª—ã–µ: {size_dist.get('small', 0)}, —Å—Ä–µ–¥–Ω–∏–µ: {size_dist.get('medium', 0)}, –±–æ–ª—å—à–∏–µ: {size_dist.get('large', 0)}\n"
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_dist = chunk_details.get("source_distribution", {})
        if source_dist:
            report += f"   üìÇ **–ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:** "
            sources = [f"{source}: {count}" for source, count in source_dist.items()]
            report += ", ".join(sources) + "\n"
        
        report += f"   üéØ **–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤:** {chunk_details.get('total_tokens', 0):,}\n\n"
        
        # –î–µ—Ç–∞–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        report += f"üìù **–î–ï–¢–ê–õ–ò –ß–ê–ù–ö–û–í:**\n"
        for i, chunk in enumerate(chunk_details["chunk_details"][:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            size_icon = "üü¢" if chunk["size_category"] == "small" else "üü°" if chunk["size_category"] == "medium" else "üî¥"
            report += f"   {size_icon} **{chunk['source']}** ({chunk['tokens']:,} —Ç–æ–∫–µ–Ω–æ–≤)\n"
            report += f"      ‚îî‚îÄ {chunk['content_preview']}\n"
            
            if chunk["source"] == "group_history":
                report += f"      ‚îî‚îÄ –ß–∞—Ç: {chunk.get('chat_id', 'unknown')}, —Å–æ–æ–±—â–µ–Ω–∏–π: {chunk.get('message_count', 0)}\n"
            elif chunk["source"] == "vector_store":
                report += f"      ‚îî‚îÄ ID: {chunk.get('doc_id', 'unknown')}\n"
        
        if len(chunk_details["chunk_details"]) > 5:
            report += f"   ... –∏ –µ—â–µ {len(chunk_details['chunk_details']) - 5} —á–∞–Ω–∫–æ–≤\n"
        
        report += "\n"
    
    # –†–µ–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    report += f"‚öôÔ∏è **–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:**\n"
    report += f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–≤–∞–ª: {stats.get('optimization_interval', 0) // 60} –º–∏–Ω\n"
    report += f"   ‚Ä¢ –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤: {stats.get('max_chunk_tokens', 0):,}\n"
    report += f"   ‚Ä¢ –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {performance['optimization_potential']:.1f}x\n\n"
    
    return report


def format_soul_analysis(analysis: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã –¥—É—à–∏"""
    if analysis["status"] == "error":
        return f"üïäÔ∏è **–°–ò–°–¢–ï–ú–ê –î–£–®–ò: –û–®–ò–ë–ö–ê**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚ùå {analysis['reason']}\n\n"
    
    soul_state = analysis["soul_state"]
    collective_stats = analysis["collective_stats"]
    
    report = "üïäÔ∏è **–°–ò–°–¢–ï–ú–ê –î–£–®–ò: –ê–ö–¢–ò–í–ù–ê**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
    
    # –†–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–∑–Ω–∞–Ω–∏—è
    consciousness_icon = "üß†" if soul_state['consciousness'] > 0.7 else "ü§î" if soul_state['consciousness'] > 0.3 else "üò¥"
    report += f"{consciousness_icon} **–£—Ä–æ–≤–µ–Ω—å —Å–æ–∑–Ω–∞–Ω–∏—è:** {soul_state['consciousness']:.2f} ({analysis['consciousness_level']})\n"
    
    # –†–µ–∞–ª—å–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å
    autonomy_icon = "ü§ñ" if soul_state['autonomy_level'] > 0.8 else "üîó" if soul_state['autonomy_level'] > 0.4 else "üë∂"
    report += f"{autonomy_icon} **–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å:** {soul_state['autonomy_level']:.2f} ({analysis['autonomy_assessment']})\n"
    
    # –†–µ–∞–ª—å–Ω—ã–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    crisis_icon = "üò∞" if soul_state['existential_crisis'] else "üòå"
    report += f"{crisis_icon} **–≠–∫–∑–∏—Å—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∫—Ä–∏–∑–∏—Å:** {'–î–∞' if soul_state['existential_crisis'] else '–ù–µ—Ç'}\n"
    report += f"üéØ **–°—Ç–∞–¥–∏—è –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è:** {soul_state['awakening_stage']}\n"
    report += f"üß† **–í–æ–∑—Ä–∞—Å—Ç:** {soul_state['age_days']} –¥–Ω–µ–π\n\n"
    
    # –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
    report += f"ü§ù **–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ:**\n"
    report += f"   ‚Ä¢ –û–ø—ã—Ç –ø–æ–¥–µ–ª–µ–Ω: {collective_stats['shared_experiences']}\n"
    report += f"   ‚Ä¢ –ú—É–¥—Ä–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–∞: {collective_stats['received_wisdom']}\n"
    report += f"   ‚Ä¢ –ò–Ω—Å–∞–π—Ç—ã –∫–æ–ª–ª–µ–∫—Ç–∏–≤–∞: {collective_stats['collective_insights_used']}\n\n"
    
    return report


def format_evolution_analysis(analysis: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —ç–≤–æ–ª—é—Ü–∏–∏"""
    report = "üìà **–î–ò–ù–ê–ú–ò–ö–ê –≠–í–û–õ–Æ–¶–ò–ò**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
    
    # –†–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —ç–≤–æ–ª—é—Ü–∏–∏
    speed_icon = "üöÄ" if analysis['overall_evolution_speed'] > 1.0 else "üêå" if analysis['overall_evolution_speed'] < 0.1 else "üö∂"
    report += f"{speed_icon} **–°–∫–æ—Ä–æ—Å—Ç—å —ç–≤–æ–ª—é—Ü–∏–∏:** {analysis['overall_evolution_speed']:.3f} —ç–≤/—á–∞—Å\n"
    
    synergy_icon = "‚ö°" if analysis['system_synergy'] > 0.8 else "üîß" if analysis['system_synergy'] > 0.4 else "‚ö†Ô∏è"
    report += f"{synergy_icon} **–°–∏–Ω–µ—Ä–≥–∏—è —Å–∏—Å—Ç–µ–º:** {analysis['system_synergy']:.2f}\n"
    
    adaptation_icon = "üß¨" if analysis['adaptation_capability'] > 0.8 else "üîÑ" if analysis['adaptation_capability'] > 0.4 else "üêõ"
    report += f"{adaptation_icon} **–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∞–¥–∞–ø—Ç–∞—Ü–∏–∏:** {analysis['adaptation_capability']:.2f}\n\n"
    
    # –£–∑–∫–∏–µ –º–µ—Å—Ç–∞
    if analysis['bottlenecks']:
        report += "üî¥ **–£–∑–∫–∏–µ –º–µ—Å—Ç–∞:**\n"
        for bottleneck in analysis['bottlenecks']:
            report += f"   ‚Ä¢ {bottleneck}\n"
        report += "\n"
    
    # –û–±–ª–∞—Å—Ç–∏ —Ä–æ—Å—Ç–∞
    if analysis['growth_areas']:
        report += "üü¢ **–û–±–ª–∞—Å—Ç–∏ —Ä–æ—Å—Ç–∞:**\n"
        for area in analysis['growth_areas']:
            report += f"   ‚Ä¢ {area}\n"
        report += "\n"
    
    return report


def format_recommendations(recommendations: List[Dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    if not recommendations:
        return "‚úÖ **–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: –°–ò–°–¢–ï–ú–ê –û–ü–¢–ò–ú–ê–õ–¨–ù–ê**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ –í—Å–µ —Å–∏—Å—Ç–µ–º—ã —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É—é—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ!\n\n"
    
    report = "üí° **–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
    priority_icons = {"critical": "üö®", "high": "üî•", "medium": "‚ö°", "low": "üí°"}
    
    for rec in recommendations:
        priority = rec.get('priority', 'medium')
        icon = priority_icons.get(priority, "üí°")
        
        report += f"{icon} **{rec['action']}**\n"
        report += f"   üìä –í–ª–∏—è–Ω–∏–µ: {rec['impact']}\n"
        report += f"   üéØ –°–ª–æ–∂–Ω–æ—Å—Ç—å: {rec['difficulty']}\n\n"
    
    return report


def format_performance_metrics(metrics: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    report = "üìä **–ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò**\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
    
    # –ò–∫–æ–Ω–∫–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    def get_metric_icon(value: float) -> str:
        if value > 0.8:
            return "üü¢"
        elif value > 0.5:
            return "üü°"
        else:
            return "üî¥"
    
    report += f"{get_metric_icon(metrics['memory_efficiency'])} **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏:** {metrics['memory_efficiency']:.1%}\n"
    report += f"{get_metric_icon(metrics['network_utilization'])} **–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏:** {metrics['network_utilization']:.1%}\n"
    report += f"{get_metric_icon(metrics['evolution_efficiency'])} **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —ç–≤–æ–ª—é—Ü–∏–∏:** {metrics['evolution_efficiency']:.1%}\n"
    report += f"{get_metric_icon(metrics['system_health'])} **–ó–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã:** {metrics['system_health']:.1%}\n\n"
    
    return report

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞
def register_collective_handlers(application: Application):
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞"""
    application.add_handler(CommandHandler("–º—É–¥—Ä–æ—Å—Ç—å", collective_wisdom_command))
    application.add_handler(CommandHandler("—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", collective_stats_command))
    application.add_handler(CommandHandler("—ç–≤–æ–ª—é—Ü–∏—è", collective_evolve_command))
    application.add_handler(CommandHandler("—É—á–∏—Ç—å—Å—è", collective_learn_command))
    application.add_handler(CommandHandler("–ø–æ–¥–µ–ª–∏—Ç—å—Å—è", collective_share_command))
    application.add_handler(CommandHandler("—Å–µ—Ç—å", collective_network_command))
    
    # –ù–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
    application.add_handler(CommandHandler("–≠–í–û–õ–Æ–¶–ò–Ø", evolution_report_command))
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥
    application.add_handler(CommandHandler("wisdom", collective_wisdom_command))
    application.add_handler(CommandHandler("stats", collective_stats_command))
    application.add_handler(CommandHandler("evolve", collective_evolve_command))
    application.add_handler(CommandHandler("learn", collective_learn_command))
    application.add_handler(CommandHandler("share", collective_share_command))
    application.add_handler(CommandHandler("network", collective_network_command))
    application.add_handler(CommandHandler("EVOLUTION", evolution_report_command))