"""
–ú–æ–¥—É–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ DeepAI API.
"""
import asyncio
import time
import logging
import aiohttp
import os
from typing import Optional, Dict, Any
import json
import re
from pathlib import Path

# –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
try:
    from backend.config import *
except ImportError:
    # Fallback –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent))
    from config import *

logger = logging.getLogger(__name__)

# Fallback –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    DEEPAI_API_KEY
except NameError:
    DEEPAI_API_KEY = os.environ.get("DEEPAI_API_KEY", "")

# DeepAI API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DEEPAI_BASE_URL = "https://api.deepai.org/api"
DEEPAI_DEFAULT_MODEL = "text2img"

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ DeepAI
DEEPAI_MODELS = {
    "text2img": {
        "name": "Text to Image",
        "description": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞",
        "endpoint": "/text2img",
        "supports_size": True,
        "max_size": 1024,
        "free_tier": True
    },
    "tor-sr": {
        "name": "Super Resolution",
        "description": "–£–ª—É—á—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
        "endpoint": "/tor-sr",
        "supports_size": False,
        "free_tier": True
    },
    "colorizer": {
        "name": "Colorizer",
        "description": "–†–∞—Å–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ —á–µ—Ä–Ω–æ-–±–µ–ª—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π",
        "endpoint": "/colorizer",
        "supports_size": False,
        "free_tier": True
    },
    "deepdream": {
        "name": "DeepDream",
        "description": "–•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
        "endpoint": "/deepdream",
        "supports_size": False,
        "free_tier": True
    },
    "waifu2x": {
        "name": "Waifu2x",
        "description": "–£–ª—É—á—à–µ–Ω–∏–µ –∞–Ω–∏–º–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
        "endpoint": "/waifu2x",
        "supports_size": False,
        "free_tier": True
    }
}

async def generate_image_deepai(
    prompt: str,
    model: str = DEEPAI_DEFAULT_MODEL,
    width: int = 512,
    height: int = 512,
    timeout: int = 300  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
) -> Optional[bytes]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ DeepAI API
    
    Args:
        prompt: –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        width: –®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        height: –í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        timeout: –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        bytes: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ bytes –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    
    if not DEEPAI_API_KEY:
        logger.error("‚ùå DEEPAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        return None
    
    if model not in DEEPAI_MODELS:
        logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º {DEEPAI_DEFAULT_MODEL}")
        model = DEEPAI_DEFAULT_MODEL
    
    model_info = DEEPAI_MODELS[model]
    endpoint = model_info["endpoint"]
    
    logger.info(f"üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ DeepAI: '{prompt[:50]}...' (–º–æ–¥–µ–ª—å: {model})")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
    data = {
        "text": prompt
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π
    if model_info["supports_size"]:
        data["width"] = str(width)
        data["height"] = str(height)
    
    headers = {
        "api-key": DEEPAI_API_KEY,
        "User-Agent": "ChatumbaAI/1.0"
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            async with session.post(
                f"{DEEPAI_BASE_URL}{endpoint}",
                headers=headers,
                data=data,
                timeout=aiohttp.ClientTimeout(total=timeout)
            ) as response:
                
                if response.status != 200:
                    error_text = await response.text()
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ DeepAI API: {response.status} - {error_text}")
                    return None
                
                result = await response.json()
                
                # –ü–æ–ª—É—á–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞
                image_url = result.get("output_url")
                if not image_url:
                    logger.error(f"‚ùå URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ: {result}")
                    return None
                
                logger.info(f"üéâ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ! –ó–∞–≥—Ä—É–∂–∞–µ–º: {image_url}")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                async with session.get(image_url, timeout=aiohttp.ClientTimeout(total=60)) as img_response:
                    if img_response.status == 200:
                        image_data = await img_response.read()
                        logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ ({len(image_data)} bytes)")
                        return image_data
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_response.status}")
                        return None
    
    except asyncio.TimeoutError:
        logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ DeepAI API")
        return None
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        return None

async def get_deepai_models() -> Dict[str, Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö DeepAI
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª—è—Ö
    """
    return DEEPAI_MODELS

def get_available_models() -> Dict[str, Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    models = {}
    
    for model_id, model_info in DEEPAI_MODELS.items():
        models[model_id] = {
            "name": model_info["name"],
            "type": "deepai",
            "description": model_info["description"],
            "max_resolution": model_info.get("max_size", 512),
            "supports_nsfw": False,  # DeepAI –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç NSFW
            "average_wait_time": "10-30 seconds",
            "free": model_info.get("free_tier", True)
        }
    
    return models

async def image_generator(
    prompt: str,
    model: str = DEEPAI_DEFAULT_MODEL,
    width: int = 512,
    height: int = 512,
    timeout: int = 300,
    **kwargs
) -> Optional[bytes]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ DeepAI
    
    Args:
        prompt: –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        width: –®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        height: –í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        timeout: –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        
    Returns:
        bytes: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ bytes
    """
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    if model not in DEEPAI_MODELS:
        logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º {DEEPAI_DEFAULT_MODEL}")
        model = DEEPAI_DEFAULT_MODEL
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    return await generate_image_deepai(
        prompt=prompt,
        model=model,
        width=width,
        height=height,
        timeout=timeout
    )

async def translate_prompt_to_english(prompt: str) -> str:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∏ —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫ —á–µ—Ä–µ–∑ OpenRouter LLM
    Args:
        prompt: –ò—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–±—ã—á–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º)
    Returns:
        str: –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –¥–ª—è text-to-image
    """
    # –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç —É–∂–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if not any(ord(char) > 127 for char in prompt):
        return prompt
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –∫–ª–∏–µ–Ω—Ç –∏–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    try:
        from utils.component_manager import get_component_manager
        component_manager = get_component_manager()
        local_llm_client = component_manager.get_llm_client()
    except ImportError:
        logger.error("Failed to import ComponentManager, returning original prompt")
        return prompt
    
    system_prompt = (
        "You are a prompt engineer for text-to-image models. Your job is to translate the user's Russian request to English for image generation. "
        "Strictly preserve all key details, numbers, objects, actions, and relationships from the original prompt. "
        "Do NOT add, remove, or change the number of people, animals, or objects. Do NOT reinterpret, generalize, or average the request. "
        "You may add a few stylistic details (lighting, style, quality) ONLY if they do not change the meaning. "
        "Output strictly in JSON: {\"prompt\": \"...\"} with no extra text.\n"
        "Examples:\n"
        "Input: '—Ç—Ä–∏ —á–µ–ª–æ–≤–µ–∫–∞ –∏ –¥–≤–µ —Å–æ–±–∞–∫–∏ –Ω–∞ –ø–ª—è–∂–µ'\nOutput: {\"prompt\": \"three people and two dogs standing on a beach, photorealistic, high quality\"}\n"
        "Input: '–¥–µ–≤—É—à–∫–∞ –¥–µ—Ä–∂–∏—Ç –≤ —Ä—É–∫–∞—Ö –∫—Ä–∞—Å–Ω—É—é –∫–Ω–∏–≥—É'\nOutput: {\"prompt\": \"a girl holding a red book, detailed, soft lighting\"}"
    )
    
    try:
        improved_response = await local_llm_client.chat_completion(
            user_message=prompt,
            system_prompt=system_prompt,
            max_tokens=200,
            temperature=0.7
        )
        if improved_response:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON —Å –∫–ª—é—á–æ–º prompt
            match = re.search(r'\{[^{}]*"prompt"\s*:\s*".*?"[^{}]*\}', improved_response, re.DOTALL)
            if match:
                try:
                    data = json.loads(match.group(0))
                    if isinstance(data, dict) and "prompt" in data:
                        logger.info(f"[PROMPT TRANSLATE] –ò—Ç–æ–≥–æ–≤—ã–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç: {data['prompt'].strip()}")
                        return data["prompt"].strip()
                except Exception as e:
                    logger.error(f"[PROMPT TRANSLATE] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            logger.error(f"[PROMPT TRANSLATE] –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON —Å –∫–ª—é—á–æ–º 'prompt' –≤ –æ—Ç–≤–µ—Ç–µ: {improved_response}")
            return prompt
        else:
            return prompt
    except Exception as e:
        logger.error(f"[PROMPT TRANSLATE] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e}")
    return prompt

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async def generate_image_stable_horde(prompt: str, model: str = DEEPAI_DEFAULT_MODEL, **kwargs) -> Optional[bytes]:
    """–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Stable Horde API"""
    return await image_generator(prompt, model, **kwargs)

async def generate_image_hf(prompt: str, model: str = DEEPAI_DEFAULT_MODEL, **kwargs) -> Optional[bytes]:
    """–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å HuggingFace API"""
    return await image_generator(prompt, model, **kwargs)

async def generate_image_replicate(prompt: str, model: str = DEEPAI_DEFAULT_MODEL, **kwargs) -> Optional[bytes]:
    """–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Replicate API"""
    return await image_generator(prompt, model, **kwargs)

if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    async def test():
        result = await image_generator("a beautiful sunset over the ocean")
        if result:
            print(f"‚úÖ –¢–µ—Å—Ç —É—Å–ø–µ—à–µ–Ω! –ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–º {len(result)} bytes")
        else:
            print("‚ùå –¢–µ—Å—Ç –Ω–µ —É–¥–∞–ª—Å—è")
    
    asyncio.run(test()) 