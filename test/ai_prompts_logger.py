#!/usr/bin/env python3
"""
üß† –õ–û–ì–ì–ï–† –ü–†–û–ú–ü–¢–û–í –ò –û–¢–í–ï–¢–û–í AI –ú–û–î–ï–õ–ï–ô
–û—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –ª–æ–≥–æ–≤ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å AI –º–æ–¥–µ–ª—è–º–∏
"""

import logging
import os
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
import hashlib
import time

class AIPromptsLogger:
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ AI –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, log_file: str = "ai_prompts.log"):
        self.log_file = Path(log_file)
        self.setup_logger()
        
    def setup_logger(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞"""
        # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        formatter = logging.Formatter(
            '%(asctime)s | %(levelname)s | %(name)s | %(funcName)s:%(lineno)d | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(formatter)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥–≥–µ—Ä
        self.logger = logging.getLogger('ai_prompts')
        self.logger.setLevel(logging.DEBUG)
        self.logger.handlers.clear()  # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        self.logger.propagate = False  # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–æ–≤
        
        # –û–¢–ö–õ–Æ–ß–ê–ï–ú DEBUG –õ–û–ì–ò –û–¢ –°–¢–û–†–û–ù–ù–ò–• –ë–ò–ë–õ–ò–û–¢–ï–ö
        try:
            from internet_intelligence_logger import disable_third_party_debug_logs
            disable_third_party_debug_logs()
        except ImportError:
            # Fallback –µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
            third_party_loggers = ['htmldate', 'trafilatura', 'newspaper', 'readability', 'justext',
                                  'bs4', 'urllib3', 'aiohttp', 'asyncio', 'charset_normalizer',
                                  'requests', 'feedparser', 'nltk', 'lxml', 'html5lib']
            for logger_name in third_party_loggers:
                logging.getLogger(logger_name).setLevel(logging.WARNING)
    
    def log_prompt_request(self, 
                          model: str, 
                          system_prompt: str, 
                          user_prompt: str, 
                          context: Dict[str, Any] = None,
                          request_id: str = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ–º–ø—Ç–∞ –∫ AI –º–æ–¥–µ–ª–∏"""
        if not request_id:
            request_id = self._generate_request_id()
        
        self.logger.info(f"üß† AI –ó–ê–ü–†–û–°: {request_id}")
        self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model}")
        self.logger.info(f"   –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç:")
        self.logger.info(f"   {system_prompt}")
        self.logger.info(f"   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç:")
        self.logger.info(f"   {user_prompt}")
        
        if context:
            self.logger.info(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {json.dumps(context, ensure_ascii=False, indent=2)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        self._save_full_prompt(request_id, model, system_prompt, user_prompt, context)
        
        return request_id
    
    def log_prompt_response(self, 
                           request_id: str, 
                           response: str, 
                           model: str, 
                           tokens_used: int = None,
                           processing_time: float = None,
                           success: bool = True,
                           error: str = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI –º–æ–¥–µ–ª–∏"""
        status_emoji = "‚úÖ" if success else "‚ùå"
        self.logger.info(f"{status_emoji} AI –û–¢–í–ï–¢: {request_id}")
        self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model}")
        self.logger.info(f"   –û—Ç–≤–µ—Ç:")
        self.logger.info(f"   {response}")
        
        if tokens_used:
            self.logger.info(f"   –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {tokens_used}")
        
        if processing_time:
            self.logger.info(f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
        
        if error:
            self.logger.error(f"   –û—à–∏–±–∫–∞: {error}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        self._save_full_response(request_id, response, model, tokens_used, processing_time, success, error)
    
    def log_prompt_conversation(self, 
                               conversation_id: str,
                               messages: List[Dict[str, str]], 
                               model: str,
                               context: Dict[str, Any] = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –±–µ—Å–µ–¥—ã —Å AI"""
        self.logger.info(f"üí¨ AI –ë–ï–°–ï–î–ê: {conversation_id}")
        self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model}")
        self.logger.info(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(messages)}")
        
        if context:
            self.logger.info(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {json.dumps(context, ensure_ascii=False, indent=2)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –±–µ—Å–µ–¥—É
        self._save_full_conversation(conversation_id, messages, model, context)
    
    def log_prompt_analysis(self, 
                           request_id: str,
                           analysis_type: str,
                           analysis_result: Dict[str, Any]):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞"""
        self.logger.info(f"üî¨ AI –ê–ù–ê–õ–ò–ó: {request_id}")
        self.logger.info(f"   –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: {analysis_type}")
        self.logger.info(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {json.dumps(analysis_result, ensure_ascii=False, indent=2)}")
    
    def log_prompt_performance(self, 
                              model: str,
                              operation: str,
                              duration: float,
                              tokens_used: int = None,
                              cost: float = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ AI –æ–ø–µ—Ä–∞—Ü–∏–π"""
        self.logger.info(f"‚ö° AI –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨: {operation}")
        self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model}")
        self.logger.info(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f}—Å")
        
        if tokens_used:
            self.logger.info(f"   –¢–æ–∫–µ–Ω–æ–≤: {tokens_used}")
        
        if cost:
            self.logger.info(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: ${cost:.6f}")
    
    def log_prompt_error(self, 
                        request_id: str,
                        error: Exception,
                        context: str = "",
                        additional_info: Dict[str, Any] = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ AI –æ–ø–µ—Ä–∞—Ü–∏–π"""
        self.logger.error(f"‚ùå AI –û–®–ò–ë–ö–ê: {request_id}")
        self.logger.error(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
        self.logger.error(f"   –¢–∏–ø –æ—à–∏–±–∫–∏: {type(error).__name__}")
        self.logger.error(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {str(error)}")
        
        if additional_info:
            self.logger.error(f"   –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {json.dumps(additional_info, ensure_ascii=False, indent=2)}")
    
    def log_model_config(self, 
                        model: str,
                        config: Dict[str, Any]):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
        self.logger.info(f"‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò: {model}")
        for key, value in config.items():
            self.logger.info(f"   {key}: {value}")
    
    def log_prompt_quality(self, 
                          request_id: str,
                          quality_metrics: Dict[str, float]):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–º–ø—Ç–∞"""
        self.logger.info(f"üìä –ö–ê–ß–ï–°–¢–í–û –ü–†–û–ú–ü–¢–ê: {request_id}")
        for metric, value in quality_metrics.items():
            self.logger.info(f"   {metric}: {value:.3f}")
    
    def _generate_request_id(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –∑–∞–ø—Ä–æ—Å–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        random_suffix = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]
        return f"ai_{timestamp}_{random_suffix}"
    
    def _save_full_prompt(self, 
                         request_id: str,
                         model: str,
                         system_prompt: str,
                         user_prompt: str,
                         context: Dict[str, Any] = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª"""
        prompt_data = {
            "request_id": request_id,
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "system_prompt": system_prompt,
            "user_prompt": user_prompt,
            "context": context or {}
        }
        
        prompt_file = self.log_file.parent / f"prompts/{request_id}_prompt.json"
        prompt_file.parent.mkdir(exist_ok=True)
        
        try:
            with open(prompt_file, 'w', encoding='utf-8') as f:
                json.dump(prompt_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞: {e}")
    
    def _save_full_response(self, 
                           request_id: str,
                           response: str,
                           model: str,
                           tokens_used: int = None,
                           processing_time: float = None,
                           success: bool = True,
                           error: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª"""
        response_data = {
            "request_id": request_id,
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "response": response,
            "tokens_used": tokens_used,
            "processing_time": processing_time,
            "success": success,
            "error": error
        }
        
        response_file = self.log_file.parent / f"responses/{request_id}_response.json"
        response_file.parent.mkdir(exist_ok=True)
        
        try:
            with open(response_file, 'w', encoding='utf-8') as f:
                json.dump(response_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: {e}")
    
    def _save_full_conversation(self, 
                               conversation_id: str,
                               messages: List[Dict[str, str]],
                               model: str,
                               context: Dict[str, Any] = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –±–µ—Å–µ–¥—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª"""
        conversation_data = {
            "conversation_id": conversation_id,
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "messages": messages,
            "context": context or {}
        }
        
        conversation_file = self.log_file.parent / f"conversations/{conversation_id}_conversation.json"
        conversation_file.parent.mkdir(exist_ok=True)
        
        try:
            with open(conversation_file, 'w', encoding='utf-8') as f:
                json.dump(conversation_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–µ—Å–µ–¥—ã: {e}")
    
    def get_log_file_path(self) -> Path:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –ª–æ–≥–æ–≤"""
        return self.log_file
    
    def get_log_file_size(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤ –≤ –±–∞–π—Ç–∞—Ö"""
        try:
            return self.log_file.stat().st_size
        except FileNotFoundError:
            return 0
    
    def get_prompts_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–º–ø—Ç–æ–≤"""
        try:
            prompts_dir = self.log_file.parent / "prompts"
            responses_dir = self.log_file.parent / "responses"
            
            stats = {
                "total_prompts": 0,
                "total_responses": 0,
                "successful_responses": 0,
                "failed_responses": 0,
                "models_used": set(),
                "average_processing_time": 0.0,
                "total_tokens": 0
            }
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã
            if prompts_dir.exists():
                stats["total_prompts"] = len(list(prompts_dir.glob("*_prompt.json")))
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã
            if responses_dir.exists():
                response_files = list(responses_dir.glob("*_response.json"))
                stats["total_responses"] = len(response_files)
                
                processing_times = []
                for response_file in response_files:
                    try:
                        with open(response_file, 'r', encoding='utf-8') as f:
                            response_data = json.load(f)
                            
                        if response_data.get("success", True):
                            stats["successful_responses"] += 1
                        else:
                            stats["failed_responses"] += 1
                        
                        stats["models_used"].add(response_data.get("model", "unknown"))
                        
                        if response_data.get("processing_time"):
                            processing_times.append(response_data["processing_time"])
                        
                        if response_data.get("tokens_used"):
                            stats["total_tokens"] += response_data["tokens_used"]
                            
                    except Exception as e:
                        self.logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –æ—Ç–≤–µ—Ç–∞ {response_file}: {e}")
                
                if processing_times:
                    stats["average_processing_time"] = sum(processing_times) / len(processing_times)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º set –≤ list –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            stats["models_used"] = list(stats["models_used"])
            
            return stats
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ª–æ–≥–≥–µ—Ä–∞
ai_prompts_logger = None

def get_ai_prompts_logger() -> AIPromptsLogger:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ª–æ–≥–≥–µ—Ä–∞ –ø—Ä–æ–º–ø—Ç–æ–≤"""
    global ai_prompts_logger
    if ai_prompts_logger is None:
        ai_prompts_logger = AIPromptsLogger()
    return ai_prompts_logger

def log_ai_prompt_operation(operation: str, **kwargs):
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏"""
    logger = get_ai_prompts_logger()
    
    if operation == "prompt_request":
        logger.log_prompt_request(
            kwargs.get('model'),
            kwargs.get('system_prompt'),
            kwargs.get('user_prompt'),
            kwargs.get('context'),
            kwargs.get('request_id')
        )
    elif operation == "prompt_response":
        logger.log_prompt_response(
            kwargs.get('request_id'),
            kwargs.get('response'),
            kwargs.get('model'),
            kwargs.get('tokens_used'),
            kwargs.get('processing_time'),
            kwargs.get('success', True),
            kwargs.get('error')
        )
    elif operation == "prompt_conversation":
        logger.log_prompt_conversation(
            kwargs.get('conversation_id'),
            kwargs.get('messages'),
            kwargs.get('model'),
            kwargs.get('context')
        )
    elif operation == "prompt_analysis":
        logger.log_prompt_analysis(
            kwargs.get('request_id'),
            kwargs.get('analysis_type'),
            kwargs.get('analysis_result')
        )
    elif operation == "prompt_performance":
        logger.log_prompt_performance(
            kwargs.get('model'),
            kwargs.get('operation'),
            kwargs.get('duration'),
            kwargs.get('tokens_used'),
            kwargs.get('cost')
        )
    elif operation == "prompt_error":
        logger.log_prompt_error(
            kwargs.get('request_id'),
            kwargs.get('error'),
            kwargs.get('context'),
            kwargs.get('additional_info')
        )
    elif operation == "model_config":
        logger.log_model_config(
            kwargs.get('model'),
            kwargs.get('config')
        )
    elif operation == "prompt_quality":
        logger.log_prompt_quality(
            kwargs.get('request_id'),
            kwargs.get('quality_metrics')
        )
    else:
        logger.logger.info(f"üìù AI –û–ü–ï–†–ê–¶–ò–Ø: {operation}")
        for key, value in kwargs.items():
            logger.logger.info(f"   {key}: {value}")

# –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è AI —Ñ—É–Ω–∫—Ü–∏–π
def log_ai_function_call(func_name: str = None):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–∑–æ–≤–æ–≤ AI —Ñ—É–Ω–∫—Ü–∏–π"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger = get_ai_prompts_logger()
            func_name_to_log = func_name or func.__name__
            
            logger.logger.debug(f"üîß –í–´–ó–û–í AI –§–£–ù–ö–¶–ò–ò: {func_name_to_log}")
            logger.logger.debug(f"   –ê—Ä–≥—É–º–µ–Ω—Ç—ã: {args}")
            logger.logger.debug(f"   –ö–ª—é—á–µ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã: {kwargs}")
            
            start_time = datetime.now()
            try:
                result = func(*args, **kwargs)
                duration = (datetime.now() - start_time).total_seconds()
                logger.logger.debug(f"‚úÖ AI –§–£–ù–ö–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê: {func_name_to_log} –∑–∞ {duration:.2f}—Å")
                return result
            except Exception as e:
                duration = (datetime.now() - start_time).total_seconds()
                logger.log_prompt_error(e, f"–û—à–∏–±–∫–∞ –≤ AI —Ñ—É–Ω–∫—Ü–∏–∏ {func_name_to_log}", {
                    "duration": f"{duration:.2f}—Å",
                    "args": str(args),
                    "kwargs": str(kwargs)
                })
                raise
        return wrapper
    return decorator

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–≥–µ—Ä–∞
    logger = get_ai_prompts_logger()
    
    # –¢–µ—Å—Ç –ø—Ä–æ–º–ø—Ç–∞
    request_id = logger.log_prompt_request(
        model="gpt-4",
        system_prompt="–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç",
        user_prompt="–†–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–≥–æ–¥–µ",
        context={"user_id": "test_user", "chat_id": "test_chat"}
    )
    
    # –¢–µ—Å—Ç –æ—Ç–≤–µ—Ç–∞
    logger.log_prompt_response(
        request_id=request_id,
        response="–ü–æ–≥–æ–¥–∞ —Å–µ–≥–æ–¥–Ω—è —Å–æ–ª–Ω–µ—á–Ω–∞—è, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 25¬∞C",
        model="gpt-4",
        tokens_used=150,
        processing_time=2.5
    )
    
    # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    logger.log_prompt_performance(
        model="gpt-4",
        operation="text_generation",
        duration=2.5,
        tokens_used=150,
        cost=0.003
    )
    
    # –¢–µ—Å—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats = logger.get_prompts_stats()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤: {stats}")
    
    print(f"‚úÖ –õ–æ–≥–≥–µ—Ä –ø—Ä–æ–º–ø—Ç–æ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω. –§–∞–π–ª: {logger.get_log_file_path()}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {logger.get_log_file_size()} –±–∞–π—Ç") 