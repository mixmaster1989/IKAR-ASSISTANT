#!/usr/bin/env python3
"""
üß™ –¢–ï–°–¢ –†–ï–ê–õ–¨–ù–û–ì–û –ü–ê–†–°–ò–ù–ì–ê
–¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö —Å–∞–π—Ç–∞—Ö
"""

import asyncio
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent))

from improved_content_extractor import get_extractor

async def test_real_parsing():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–∞–π—Ç–∞—Ö"""
    
    print("üß™ –¢–ï–°–¢ –†–ï–ê–õ–¨–ù–û–ì–û –ü–ê–†–°–ò–ù–ì–ê")
    print("=" * 60)
    
    extractor = await get_extractor()
    
    # –†–ï–ê–õ–¨–ù–´–ï —Ä–∞–±–æ—á–∏–µ URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    real_test_cases = [
        {
            "url": "https://www.interfax.ru/russia/",
            "query": "–Ω–æ–≤–æ—Å—Ç–∏ —Ä–æ—Å—Å–∏—è",
            "expected_type": "news"
        },
        {
            "url": "https://habr.com/ru/",
            "query": "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            "expected_type": "blog"
        },
        {
            "url": "https://www.rbc.ru/",
            "query": "–Ω–æ–≤–æ—Å—Ç–∏",
            "expected_type": "news"
        },
        {
            "url": "https://ria.ru/",
            "query": "–Ω–æ–≤–æ—Å—Ç–∏ —Å–µ–≥–æ–¥–Ω—è",
            "expected_type": "news"
        },
        {
            "url": "https://ru.wikipedia.org/wiki/–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "query": "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "expected_type": "wikipedia"
        }
    ]
    
    print("üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ï–ê–õ–¨–ù–û–ì–û –ü–ê–†–°–ò–ù–ì–ê:")
    print("-" * 60)
    
    successful_tests = []
    failed_tests = []
    
    for i, test_case in enumerate(real_test_cases, 1):
        print(f"\n{i}. {test_case['url']}")
        print(f"   –ó–∞–ø—Ä–æ—Å: '{test_case['query']}'")
        print(f"   –û–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø: {test_case['expected_type']}")
        
        try:
            content = await extractor.extract_content(test_case['url'], test_case['query'])
            
            if content:
                print(f"   ‚úÖ –£–°–ü–ï–•")
                print(f"   üìù –ú–µ—Ç–æ–¥: {content.extraction_method}")
                print(f"   üìä –°–ª–æ–≤: {content.word_count}")
                print(f"   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {content.relevance_score:.2f}")
                print(f"   üì∞ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {content.title[:100]}...")
                print(f"   üë§ –ê–≤—Ç–æ—Ä: {content.author or '–ù–µ —É–∫–∞–∑–∞–Ω'}")
                print(f"   üìÖ –î–∞—Ç–∞: {content.publish_date or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}")
                print(f"   üìÑ –ü—Ä–µ–≤—å—é: {content.text[:200]}...")
                
                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                quality_score = 0
                if content.word_count > 200:
                    quality_score += 1
                if content.relevance_score > 0.5:
                    quality_score += 1
                if content.title:
                    quality_score += 1
                if content.author:
                    quality_score += 1
                
                quality_text = "–û—Ç–ª–∏—á–Ω–æ" if quality_score >= 3 else "–•–æ—Ä–æ—à–æ" if quality_score >= 2 else "–ü–ª–æ—Ö–æ"
                print(f"   ‚≠ê –ö–∞—á–µ—Å—Ç–≤–æ: {quality_text} ({quality_score}/4)")
                
                successful_tests.append({
                    'url': test_case['url'],
                    'content': content,
                    'quality_score': quality_score
                })
                
            else:
                print(f"   ‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –ò–ó–í–õ–ï–ß–¨ –ö–û–ù–¢–ï–ù–¢")
                failed_tests.append({
                    'url': test_case['url'],
                    'reason': 'No content extracted'
                })
                
        except Exception as e:
            print(f"   üí• –û–®–ò–ë–ö–ê: {e}")
            failed_tests.append({
                'url': test_case['url'],
                'reason': str(e)
            })
        
        print("-" * 40)
    
    print("\n" + "=" * 60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ï–ê–õ–¨–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_tests = len(real_test_cases)
    successful_extractions = len(successful_tests)
    
    print(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
    print(f"–£—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π: {successful_extractions}")
    print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(successful_extractions/total_tests)*100:.1f}%")
    
    if successful_extractions > 0:
        total_words = sum(t['content'].word_count for t in successful_tests)
        total_relevance = sum(t['content'].relevance_score for t in successful_tests)
        avg_quality = sum(t['quality_score'] for t in successful_tests) / successful_extractions
        
        print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {total_words/successful_extractions:.0f}")
        print(f"–°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {total_relevance/successful_extractions:.2f}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality:.1f}/4")
        
        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–≤
        methods = {}
        for test in successful_tests:
            method = test['content'].extraction_method
            methods[method] = methods.get(method, 0) + 1
        
        print(f"\nüìà –ê–ù–ê–õ–ò–ó –ú–ï–¢–û–î–û–í:")
        for method, count in methods.items():
            print(f"   {method}: {count} —Ä–∞–∑")
        
        # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        best_test = max(successful_tests, key=lambda x: x['quality_score'])
        print(f"\nüèÜ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(f"   URL: {best_test['url']}")
        print(f"   –ú–µ—Ç–æ–¥: {best_test['content'].extraction_method}")
        print(f"   –°–ª–æ–≤: {best_test['content'].word_count}")
        print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {best_test['content'].relevance_score:.2f}")
        print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {best_test['quality_score']}/4")
    
    if failed_tests:
        print(f"\n‚ùå –ù–ï–£–î–ê–ß–ù–´–ï –¢–ï–°–¢–´:")
        for test in failed_tests:
            print(f"   {test['url']}: {test['reason']}")
    
    await extractor.close()

if __name__ == "__main__":
    asyncio.run(test_real_parsing()) 