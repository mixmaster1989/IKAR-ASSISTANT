#!/usr/bin/env python3
"""
üß™ –¢–ï–°–¢ –ü–û–õ–ù–û–ô –ò–ù–¢–ï–†–ù–ï–¢-–ò–ù–¢–ï–õ–õ–ï–ö–¢ –°–ò–°–¢–ï–ú–´
–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å—é —Å–∏—Å—Ç–µ–º—É —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º
"""

import asyncio
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent))

from internet_intelligence_system import get_internet_system

async def test_full_system():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    
    print("üß™ –¢–ï–°–¢ –ü–û–õ–ù–û–ô –ò–ù–¢–ï–†–ù–ï–¢-–ò–ù–¢–ï–õ–õ–ï–ö–¢ –°–ò–°–¢–ï–ú–´")
    print("=" * 70)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    system = await get_internet_system()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–Ω–æ–≤–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π —Å–µ–≥–æ–¥–Ω—è",
        "–∫—É—Ä—Å –±–∏—Ç–∫–æ–∏–Ω–∞ —Å–µ–π—á–∞—Å",
        "–ø–æ–≥–æ–¥–∞ –≤ –º–æ—Å–∫–≤–µ",
        "–ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ —Ä–æ—Å—Å–∏–∏",
        "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç 2024"
    ]
    
    print("üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–õ–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print("-" * 70)
    
    successful_tests = []
    failed_tests = []
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{i}. –ó–∞–ø—Ä–æ—Å: '{query}'")
        print("-" * 50)
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç
            result = await system.get_internet_intelligence(query)
            
            if result and result.search_results:
                print(f"   ‚úÖ –£–°–ü–ï–•")
                print(f"   üîç –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(result.search_results)}")
                print(f"   üìä –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.processing_time:.2f} —Å–µ–∫")
                print(f"   üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence_score:.2f}")
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                total_words = 0
                total_relevance = 0
                extraction_methods = {}
                successful_extractions = 0
                
                for search_result in result.search_results:
                    if search_result.content and len(search_result.content) > 50:
                        successful_extractions += 1
                        total_words += len(search_result.content.split())
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Ç–æ–¥–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                        if hasattr(search_result, 'processed_content') and search_result.processed_content:
                            method = search_result.processed_content.get('extraction_method', 'unknown')
                            relevance = search_result.processed_content.get('relevance_score', 0)
                        else:
                            method = 'legacy'
                            relevance = 0
                        
                        extraction_methods[method] = extraction_methods.get(method, 0) + 1
                        total_relevance += relevance
                
                if successful_extractions > 0:
                    avg_words = total_words / successful_extractions
                    avg_relevance = total_relevance / successful_extractions
                    
                    print(f"   üìÑ –£—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π: {successful_extractions}")
                    print(f"   üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {avg_words:.0f}")
                    print(f"   üéØ –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_relevance:.2f}")
                    
                    print(f"   üìà –ú–µ—Ç–æ–¥—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:")
                    for method, count in extraction_methods.items():
                        print(f"      {method}: {count} —Ä–∞–∑")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º AI-–≤—ã–∂–∏–º–∫—É
                    if result.ai_summary:
                        print(f"   ü§ñ AI-–≤—ã–∂–∏–º–∫–∞: {result.ai_summary[:200]}...")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
                    if result.key_points:
                        print(f"   üîë –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:")
                        for point in result.key_points[:3]:
                            print(f"      ‚Ä¢ {point}")
                    
                    successful_tests.append({
                        'query': query,
                        'result': result,
                        'successful_extractions': successful_extractions,
                        'avg_words': avg_words,
                        'avg_relevance': avg_relevance
                    })
                else:
                    print(f"   ‚ö†Ô∏è –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω")
                    failed_tests.append({
                        'query': query,
                        'reason': 'No content extracted'
                    })
            else:
                print(f"   ‚ùå –ù–ï–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
                failed_tests.append({
                    'query': query,
                    'reason': 'No search results'
                })
                
        except Exception as e:
            print(f"   üí• –û–®–ò–ë–ö–ê: {e}")
            failed_tests.append({
                'query': query,
                'reason': str(e)
            })
        
        print("-" * 50)
    
    print("\n" + "=" * 70)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_tests = len(test_queries)
    successful_system_tests = len(successful_tests)
    
    print(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
    print(f"–£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã: {successful_system_tests}")
    print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞ —Å–∏—Å—Ç–µ–º—ã: {(successful_system_tests/total_tests)*100:.1f}%")
    
    if successful_system_tests > 0:
        total_extractions = sum(t['successful_extractions'] for t in successful_tests)
        avg_words = sum(t['avg_words'] for t in successful_tests) / successful_system_tests
        avg_relevance = sum(t['avg_relevance'] for t in successful_tests) / successful_system_tests
        avg_processing_time = sum(t['result'].processing_time for t in successful_tests) / successful_system_tests
        
        print(f"–í—Å–µ–≥–æ —É—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π: {total_extractions}")
        print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {avg_words:.0f}")
        print(f"–°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_relevance:.2f}")
        print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {avg_processing_time:.2f} —Å–µ–∫")
        
        # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        best_test = max(successful_tests, key=lambda x: x['avg_relevance'])
        print(f"\nüèÜ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(f"   –ó–∞–ø—Ä–æ—Å: '{best_test['query']}'")
        print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {best_test['avg_relevance']:.2f}")
        print(f"   –°–ª–æ–≤: {best_test['avg_words']:.0f}")
        print(f"   –ò–∑–≤–ª–µ—á–µ–Ω–∏–π: {best_test['successful_extractions']}")
    
    if failed_tests:
        print(f"\n‚ùå –ù–ï–£–î–ê–ß–ù–´–ï –¢–ï–°–¢–´:")
        for test in failed_tests:
            print(f"   '{test['query']}': {test['reason']}")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    await system.close()
    
    print(f"\nüéØ –í–´–í–û–î:")
    if successful_system_tests > 0:
        print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ! –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç.")
        print(f"üìà –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —É–ª—É—á—à–∏–ª–∞—Å—å —Å 30-40% –¥–æ {avg_relevance*100:.0f}%")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ —É–≤–µ–ª–∏—á–∏–ª–æ—Å—å –¥–æ {avg_words:.0f} –≤ —Å—Ä–µ–¥–Ω–µ–º")
    else:
        print(f"‚ùå –°–∏—Å—Ç–µ–º–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.")

if __name__ == "__main__":
    asyncio.run(test_full_system()) 