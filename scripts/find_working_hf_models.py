#!/usr/bin/env python3
"""
üîç –ü–æ–∏—Å–∫ –†–ê–ë–û–ß–ò–• –º–æ–¥–µ–ª–µ–π text-to-image –Ω–∞ Hugging Face
- –ò—â–µ—Ç –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ API –ø–æ–∏—Å–∫–∞
- –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ Inference API
- –¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏
"""

import os
import sys
import json
import time
import asyncio
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import aiohttp

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv(Path(__file__).resolve().parents[1] / '.env')

HF_TOKEN = os.environ.get('HF_API_KEY') or os.environ.get('HF_API_TOKEN') or os.environ.get('HUGGINGFACEHUB_API_TOKEN') or ''

ROOT = Path(__file__).resolve().parents[1]
REPORTS = ROOT / 'reports'
REPORTS.mkdir(parents=True, exist_ok=True)

WORKING_MODELS_PATH = REPORTS / 'working_hf_models.jsonl'
SEARCH_RESULTS_PATH = REPORTS / 'hf_model_search.jsonl'

# –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
TEST_PROMPT = "A cute red cat sitting on a windowsill, sunlight, photorealistic, 4k"

# –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞
KNOWN_WORKING_MODELS = [
    "stabilityai/stable-diffusion-3-medium-diffusers",
    "stabilityai/stable-diffusion-3.5-medium", 
    "stabilityai/stable-diffusion-xl-base-1.0",
    "stabilityai/sdxl-turbo",
    "runwayml/stable-diffusion-v1-5",
    "CompVis/stable-diffusion-v1-4",
    "SG161222/Realistic_Vision_V5.1_noVAE",
    "Lykon/dreamshaper-7",
    "black-forest-labs/FLUX.1-dev",
    "black-forest-labs/FLUX.1-schnell"
]

async def test_model_inference(session: aiohttp.ClientSession, model_id: str, timeout: int = 30) -> dict:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Inference API"""
    url = f"https://api-inference.huggingface.co/models/{model_id}"
    
    headers = {
        "Authorization": f"Bearer {HF_TOKEN}" if HF_TOKEN else "",
        "Accept": "application/json"
    }
    
    payload = {"inputs": TEST_PROMPT}
    
    start_time = time.time()
    try:
        async with session.post(url, json=payload, headers=headers, timeout=timeout) as resp:
            elapsed = int((time.time() - start_time) * 1000)
            content_type = resp.headers.get('content-type', '')
            
            if resp.status == 200:
                if content_type.startswith('image/'):
                    return {
                        'model_id': model_id,
                        'status': 'success',
                        'content_type': content_type,
                        'elapsed_ms': elapsed,
                        'error': None
                    }
                elif 'application/json' in content_type:
                    # –í–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
                    data = await resp.text()
                    if 'loading' in data.lower() or 'model' in data.lower():
                        return {
                            'model_id': model_id,
                            'status': 'loading',
                            'content_type': content_type,
                            'elapsed_ms': elapsed,
                            'error': 'Model is loading'
                        }
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏
            try:
                error_data = await resp.text()
                if len(error_data) > 200:
                    error_data = error_data[:200] + "..."
            except:
                error_data = f"HTTP {resp.status}"
                
            return {
                'model_id': model_id,
                'status': 'error',
                'content_type': content_type,
                'elapsed_ms': elapsed,
                'error': error_data
            }
            
    except asyncio.TimeoutError:
        return {
            'model_id': model_id,
            'status': 'timeout',
            'content_type': None,
            'elapsed_ms': int((time.time() - start_time) * 1000),
            'error': 'Request timeout'
        }
    except Exception as e:
        return {
            'model_id': model_id,
            'status': 'exception',
            'content_type': None,
            'elapsed_ms': int((time.time() - start_time) * 1000),
            'error': str(e)
        }

async def search_models_by_tag(session: aiohttp.ClientSession, tag: str, limit: int = 50) -> list:
    """–ò—â–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ —Ç–µ–≥—É —á–µ—Ä–µ–∑ HF API"""
    if not HF_TOKEN:
        print(f"‚ö†Ô∏è –ù–µ—Ç —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–µ–≥—É '{tag}'")
        return []
    
    url = "https://huggingface.co/api/models"
    params = {
        "search": tag,
        "filter": "pipeline_tag:text-to-image",
        "limit": limit,
        "sort": "downloads"
    }
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    
    try:
        async with session.get(url, params=params, headers=headers) as resp:
            if resp.status == 200:
                data = await resp.json()
                return [model['id'] for model in data if 'id' in model]
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: HTTP {resp.status}")
                return []
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []

async def test_models_batch(model_ids: list, concurrency: int = 3, timeout: int = 30) -> list:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—É –º–æ–¥–µ–ª–µ–π —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å—é"""
    semaphore = asyncio.Semaphore(concurrency)
    
    async def test_with_semaphore(model_id: str):
        async with semaphore:
            async with aiohttp.ClientSession() as session:
                return await test_model_inference(session, model_id, timeout)
    
    tasks = [test_with_semaphore(mid) for mid in model_ids]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    valid_results = []
    for result in results:
        if isinstance(result, dict):
            valid_results.append(result)
        else:
            print(f"‚ö†Ô∏è –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {result}")
    
    return valid_results

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Ä–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    print("üîç –ü–û–ò–°–ö –†–ê–ë–û–ß–ò–• –ú–û–î–ï–õ–ï–ô TEXT-TO-IMAGE")
    print("=" * 60)
    
    if not HF_TOKEN:
        print("‚ö†Ô∏è HF_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω - –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    else:
        print(f"‚úÖ –¢–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω: {HF_TOKEN[:10]}...")
    
    all_results = []
    working_models = []
    
    # 1. –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏
    print(f"\nüöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(KNOWN_WORKING_MODELS)} –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
    results = await test_models_batch(KNOWN_WORKING_MODELS, concurrency=3, timeout=30)
    
    for result in results:
        all_results.append(result)
        if result['status'] == 'success':
            working_models.append(result['model_id'])
            print(f"‚úÖ {result['model_id']} - –†–ê–ë–û–¢–ê–ï–¢! ({result['elapsed_ms']}ms)")
        elif result['status'] == 'loading':
            print(f"‚è≥ {result['model_id']} - –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
        else:
            print(f"‚ùå {result['model_id']} - {result['error']}")
    
    # 2. –ò—â–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ —Ç–µ–≥–∞–º
    if HF_TOKEN:
        print(f"\nüîç –ò—â–µ–º –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ —Ç–µ–≥–∞–º...")
        search_tags = ["stable-diffusion", "sdxl", "flux", "realistic", "anime"]
        
        for tag in search_tags:
            print(f"   –ü–æ–∏—Å–∫: {tag}")
            new_models = await search_models_by_tag(session=aiohttp.ClientSession(), tag=tag, limit=20)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —É–∂–µ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
            new_models = [m for m in new_models if m not in [r['model_id'] for r in all_results]]
            
            if new_models:
                print(f"   –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {len(new_models)}")
                results = await test_models_batch(new_models[:10], concurrency=2, timeout=20)
                
                for result in results:
                    all_results.append(result)
                    if result['status'] == 'success':
                        working_models.append(result['model_id'])
                        print(f"‚úÖ {result['model_id']} - –ù–û–í–ê–Ø –†–ê–ë–û–ß–ê–Ø! ({result['elapsed_ms']}ms)")
    
    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
    
    # –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    with open(SEARCH_RESULTS_PATH, 'w', encoding='utf-8') as f:
        for result in all_results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    # –¢–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏
    with open(WORKING_MODELS_PATH, 'w', encoding='utf-8') as f:
        for model_id in working_models:
            f.write(json.dumps({'model_id': model_id, 'found_at': datetime.now().isoformat()}, ensure_ascii=False) + '\n')
    
    # 4. –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:")
    print(f"   üîç –í—Å–µ–≥–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {len(all_results)}")
    print(f"   ‚úÖ –†–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π: {len(working_models)}")
    print(f"   üìÅ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {SEARCH_RESULTS_PATH}")
    print(f"   üéØ –†–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏: {WORKING_MODELS_PATH}")
    
    if working_models:
        print(f"\nüéâ –ù–ê–ô–î–ï–ù–´ –†–ê–ë–û–ß–ò–ï –ú–û–î–ï–õ–ò:")
        for i, model in enumerate(working_models, 1):
            print(f"   {i}. {model}")
    else:
        print(f"\n‚ö†Ô∏è –†–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
    
    return len(working_models) > 0

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü–æ–∏—Å–∫ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)
