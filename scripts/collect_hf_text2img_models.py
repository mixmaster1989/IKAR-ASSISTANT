#!/usr/bin/env python3
"""
–°–±–æ—Ä –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (text-to-image) —Å Hugging Face.
- –ò—â–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Ñ–∏–ª—å—Ç—Ä–∞–º (pipeline_tag, library, –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
- –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ reports/hf_text2img_models.jsonl –∏ .csv

–ó–∞–ø—É—Å–∫:
  python3 scripts/collect_hf_text2img_models.py --limit 1500

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –°–∫—Ä–∏–ø—Ç —Ç–æ–ª—å–∫–æ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –Ω–∏—á–µ–≥–æ –Ω–µ —Å–∫–∞—á–∏–≤–∞–µ—Ç.
"""

import os
import sys
import csv
import json
import argparse
from pathlib import Path
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ .env (–ù–ï –º–µ–Ω—è–µ–º .env –∏ –Ω–µ —Ç—Ä–µ–±—É–µ–º –µ–≥–æ –Ω–∞–ª–∏—á–∏—è)
load_dotenv(Path(__file__).resolve().parents[1] / '.env')

try:
	from huggingface_hub import HfApi
	# –í –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö ModelFilter –∑–∞–º–µ–Ω–µ–Ω –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ list_models
except Exception as e:
	print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å huggingface_hub. –î–æ–±–∞–≤—å—Ç–µ 'huggingface_hub' –≤ requirements.txt")
	raise

OUTPUT_DIR = Path(__file__).resolve().parents[1] / 'reports'
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
JSONL_PATH = OUTPUT_DIR / 'hf_text2img_models.jsonl'
CSV_PATH = OUTPUT_DIR / 'hf_text2img_models.csv'

KEYWORD_QUERIES = [
	"text-to-image",
	"stable-diffusion",
	"sdxl",
	"sd 1.5",
	"kandinsky",
	"anything v4",
	"realistic vision",
	"flux",
	"animated",
	"cartoon",
]


def model_to_row(m) -> dict:
	"""–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π –∏–∑ ModelInfo."""
	return {
		'modelId': getattr(m, 'modelId', getattr(m, 'id', '')),
		'pipeline_tag': getattr(m, 'pipeline_tag', ''),
		'library': getattr(m, 'library_name', ''),
		'likes': getattr(m, 'likes', 0) or 0,
		'downloads': getattr(m, 'downloads', 0) or 0,
		'private': bool(getattr(m, 'private', False)),
		'gated': bool(getattr(m, 'gated', False)),
		'lastModified': str(getattr(m, 'lastModified', '')),
	}


def save_results(models: list):
	# –°–æ—Ö—Ä–∞–Ω—è–µ–º JSONL
	with open(JSONL_PATH, 'w', encoding='utf-8') as jf:
		for row in models:
			jf.write(json.dumps(row, ensure_ascii=False) + "\n")
	# –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV
	fieldnames = list(models[0].keys()) if models else [
		'modelId','pipeline_tag','library','likes','downloads','private','gated','lastModified']
	with open(CSV_PATH, 'w', newline='', encoding='utf-8') as cf:
		writer = csv.DictWriter(cf, fieldnames=fieldnames)
		writer.writeheader()
		writer.writerows(models)
	print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(models)} –º–æ–¥–µ–ª–µ–π -> {JSONL_PATH} –∏ {CSV_PATH}")


def main():
	parser = argparse.ArgumentParser()
	parser.add_argument('--limit', type=int, default=1500, help='–ú–∞–∫—Å–∏–º—É–º –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ñ–∏–ª—å—Ç—Ä')
	args = parser.parse_args()

	api = HfApi()
	all_rows = {}

	# 1) –ë–∞–∑–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä: diffusers + pipeline_tag text-to-image
	try:
		models = api.list_models(
			library="diffusers",
			pipeline_tag="text-to-image",
			limit=args.limit,
			sort='downloads'
		)
		for m in models:
			row = model_to_row(m)
			if row['modelId']:
				all_rows[row['modelId']] = row
		count = 0
		for m in models:
			row = model_to_row(m)
			if row['modelId']:
				all_rows[row['modelId']] = row
				count += 1
		print(f"üîé –ù–∞–π–¥–µ–Ω–æ (diffusers + text-to-image): {count}")
	except Exception as e:
		print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ diffusers/text-to-image: {e}")

	# 2) –¢–æ–ª—å–∫–æ pipeline_tag text-to-image (–ª—é–±–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞)
	try:
		models = api.list_models(
			pipeline_tag="text-to-image",
			limit=args.limit,
			sort='downloads'
		)
		count = 0
		for m in models:
			row = model_to_row(m)
			if row['modelId']:
				all_rows[row['modelId']] = row
				count += 1
		print(f"üîé –ù–∞–π–¥–µ–Ω–æ (pipeline_tag=text-to-image): {count}")
	except Exception as e:
		print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ pipeline_tag=text-to-image: {e}")

	# 3) –ü–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–¥–æ–±–∞–≤–æ—á–Ω—ã–µ –æ—Ö–≤–∞—Ç—ã)
	for q in KEYWORD_QUERIES:
		try:
			models = api.list_models(search=q, limit=args.limit, sort='downloads')
			count = 0
			for m in models:
				row = model_to_row(m)
				if row['modelId']:
					all_rows[row['modelId']] = row
					count += 1
			print(f"üîé –ù–∞–π–¥–µ–Ω–æ ('{q}'): {count}")
		except Exception as e:
			print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{q}': {e}")

	# –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
	rows = list(all_rows.values())
	rows.sort(key=lambda r: (-int(r.get('downloads', 0) or 0), -int(r.get('likes', 0) or 0)))

	save_results(rows)


if __name__ == '__main__':
	main()
