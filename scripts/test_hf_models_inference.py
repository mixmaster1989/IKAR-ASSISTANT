#!/usr/bin/env python3
"""
–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç–µ—Ä Hugging Face Inference API –¥–ª—è –º–æ–¥–µ–ª–µ–π text-to-image.
- –ß–∏—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ reports/hf_text2img_models.jsonl (–µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏—Ç —Å–Ω–∞—á–∞–ª–∞ —Å–æ–±—Ä–∞—Ç—å)
- –®–ª–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –Ω–∞ /models/{model_id}
- –§–∏–∫—Å–∏—Ä—É–µ—Ç —É—Å–ø–µ—Ö (image/*) –∏–ª–∏ –æ—à–∏–±–∫—É (JSON)
- –ü–∏—à–µ—Ç –ª–æ–≥–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ reports/hf_inference_test_results.jsonl

–í–ù–ò–ú–ê–ù–ò–ï: –ù–ò–ß–ï–ì–û –ù–ï –ó–ê–ü–£–°–ö–ê–ï–¢–°–Ø –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò –ë–ï–ó –†–ê–ó–†–ï–®–ï–ù–ò–Ø.
–ó–∞–ø—É—Å–∫ (–ø–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è):
  python3 scripts/test_hf_models_inference.py --max 400 --concurrency 3 --timeout 45
"""

import os
import sys
import json
import time
import argparse
import signal
from pathlib import Path
from typing import Optional, Tuple
import asyncio
from datetime import datetime

from dotenv import load_dotenv
import aiohttp

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv(Path(__file__).resolve().parents[1] / '.env')

HF_TOKEN = os.environ.get('HF_API_KEY') or os.environ.get('HF_API_TOKEN') or os.environ.get('HUGGINGFACEHUB_API_TOKEN') or ''
API_URL_BASE = 'https://api-inference.huggingface.co/models/'

ROOT = Path(__file__).resolve().parents[1]
REPORTS = ROOT / 'reports'
REPORTS.mkdir(parents=True, exist_ok=True)
MODELS_JSONL = REPORTS / 'hf_text2img_models.jsonl'
RESULTS_JSONL = REPORTS / 'hf_inference_test_results.jsonl'

TEST_PROMPT = (
	"A realistic red cat on a windowsill, sunlight, cozy atmosphere, photorealistic, 4k, high detail"
)

HEADERS = {
	"Accept": "image/png,image/jpeg,image/jpg,image/webp,application/json",
}
if HF_TOKEN:
	HEADERS["Authorization"] = f"Bearer {HF_TOKEN}"


def load_models(max_models: int) -> list:
	"""–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ JSONL, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç max_models."""
	if not MODELS_JSONL.exists():
		raise FileNotFoundError(
			f"–ù–µ –Ω–∞–π–¥–µ–Ω {MODELS_JSONL}. –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏: python3 scripts/collect_hf_text2img_models.py"
		)
	models = []
	with open(MODELS_JSONL, 'r', encoding='utf-8') as f:
		for line in f:
			try:
				obj = json.loads(line)
				mid = obj.get('modelId') or obj.get('id')
				if not mid:
					continue
				# –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —è–≤–Ω—ã–µ text-to-image
				ptag = (obj.get('pipeline_tag') or '').lower()
				if 'text-to-image' in ptag or 'text2image' in ptag or 'text2img' in ptag:
					models.append(mid)
				else:
					# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ö–≤–∞—Ç diffusers/stable-diffusion
					lib = (obj.get('library') or '').lower()
					name = mid.lower()
					if 'diffusers' in lib or 'stable-diffusion' in name or 'sdxl' in name or 'flux' in name:
						models.append(mid)
			except:
				continue
	# –î–µ–¥—É–ø –∏ —É—Å–µ—á–µ–Ω–∏–µ
	seen = set()
	uniq = []
	for m in models:
		if m not in seen:
			uniq.append(m)
			seen.add(m)
	return uniq[:max_models]


async def test_model(session: aiohttp.ClientSession, model_id: str, timeout: int) -> Tuple[str, str, Optional[str], int]:
	"""–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (model_id, status, error, elapsed_ms). –£—Å–ø–µ—Ö, –µ—Å–ª–∏ image/*."""
	url = API_URL_BASE + model_id
	payload = {"inputs": TEST_PROMPT}
	start = time.time()
	try:
		async with session.post(url, json=payload, timeout=timeout) as resp:
			ct = resp.headers.get('content-type', '')
			data = await resp.read()
			elapsed = int((time.time() - start) * 1000)
			if resp.status == 200 and ct.startswith('image/'):
				return (model_id, 'success', None, elapsed)
			# –ò–Ω–∞—á–µ –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—à–∏–±–∫—É
			try:
				err = json.loads(data.decode('utf-8'))
				err_msg = err.get('error') or err.get('message') or str(err)
			except Exception:
				err_msg = f"HTTP {resp.status}, content-type={ct}"
			return (model_id, 'error', err_msg, elapsed)
	except asyncio.TimeoutError:
		elapsed = int((time.time() - start) * 1000)
		return (model_id, 'timeout', 'request timed out', elapsed)
	except Exception as e:
		elapsed = int((time.time() - start) * 1000)
		return (model_id, 'exception', str(e), elapsed)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
shutdown_requested = False
completed_count = 0

def signal_handler(signum, frame):
	global shutdown_requested
	print(f"\n‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum}, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
	shutdown_requested = True

async def run(max_models: int, concurrency: int, timeout: int, resume: bool):
	global completed_count
	
	# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
	signal.signal(signal.SIGINT, signal_handler)
	signal.signal(signal.SIGTERM, signal_handler)
	
	models = load_models(max_models)
	print(f"üî¢ –ö —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é: {len(models)} –º–æ–¥–µ–ª–µ–π")

	# –†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —É–∂–µ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –º–æ–¥–µ–ª—è–º
	already = set()
	if resume and RESULTS_JSONL.exists():
		with open(RESULTS_JSONL, 'r', encoding='utf-8') as rf:
			for line in rf:
				try:
					obj = json.loads(line)
					already.add(obj.get('model_id'))
				except:
					continue
	if already:
		models = [m for m in models if m not in already]
		print(f"‚è© –ü—Ä–æ–ø—É—â–µ–Ω–æ —É–∂–µ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {len(already)} | –û—Å—Ç–∞–ª–æ—Å—å: {len(models)}")
	
	# –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–µ—Å—Ç–µ
	meta_path = REPORTS / 'hf_inference_test_meta.json'
	meta = {
		'started_at': datetime.now().isoformat(),
		'total_models': len(models),
		'already_tested': len(already),
		'concurrency': concurrency,
		'timeout': timeout,
		'test_prompt': TEST_PROMPT
	}
	with open(meta_path, 'w', encoding='utf-8') as mf:
		json.dump(meta, mf, ensure_ascii=False, indent=2)
	print(f"üìã –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {meta_path}")

	sem = asyncio.Semaphore(concurrency)

	async def bound_test(mid: str):
		async with sem:
			async with aiohttp.ClientSession(headers=HEADERS) as session:
				res = await test_model(session, mid, timeout)
				# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏
				record = {
					'model_id': res[0],
					'status': res[1],
					'error': res[2],
					'elapsed_ms': res[3],
					'tested_at': datetime.now().isoformat()
				}
				with open(RESULTS_JSONL, 'a', encoding='utf-8') as wf:
					wf.write(json.dumps(record, ensure_ascii=False) + "\n")
				print(f"[{res[1]:>9}] {mid} | {res[3]} ms | {res[2] or ''}")

	# –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ, —á—Ç–æ–±—ã –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É
	start_time = time.time()
	completed = 0
	
	print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(models)} –º–æ–¥–µ–ª–µ–π...")
	print(f"üìä –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å: {concurrency}, —Ç–∞–π–º–∞—É—Ç: {timeout}—Å")
	print("üí° –ü—Ä–µ—Ä–≤–∞—Ç—å –º–æ–∂–Ω–æ –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç (Ctrl+C) - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è\n")
	
	try:
		for i, mid in enumerate(models, 1):
			if shutdown_requested:
				print(f"\n‚ö†Ô∏è –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø–æ —Å–∏–≥–Ω–∞–ª—É –Ω–∞ –º–æ–¥–µ–ª–∏ {i-1}/{len(models)}")
				break
				
			await bound_test(mid)
			completed_count = i
			
			# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 –º–æ–¥–µ–ª–µ–π
			if i % 10 == 0:
				elapsed = time.time() - start_time
				rate = i / elapsed if elapsed > 0 else 0
				eta = (len(models) - i) / rate if rate > 0 else 0
				print(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(models)} ({i/len(models)*100:.1f}%) | –°–∫–æ—Ä–æ—Å—Ç—å: {rate:.1f} –º–æ–¥/—Å | –û—Å—Ç–∞–ª–æ—Å—å: {eta/60:.1f} –º–∏–Ω")
				
	except KeyboardInterrupt:
		print(f"\n‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –Ω–∞ –º–æ–¥–µ–ª–∏ {completed_count}/{len(models)}")
		print("üíæ –í—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
	except Exception as e:
		print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
		print("üíæ –í—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
	
	# –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
	total_time = time.time() - start_time
	success_count = 0
	error_count = 0
	timeout_count = 0
	
	if RESULTS_JSONL.exists():
		with open(RESULTS_JSONL, 'r', encoding='utf-8') as rf:
			for line in rf:
				try:
					obj = json.loads(line)
					status = obj.get('status', '')
					if status == 'success':
						success_count += 1
					elif status == 'error':
						error_count += 1
					elif status == 'timeout':
						timeout_count += 1
				except:
					continue
	
	print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
	print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {success_count}")
	print(f"   ‚ùå –û—à–∏–±–∫–∏: {error_count}")
	print(f"   ‚è∞ –¢–∞–π–º–∞—É—Ç—ã: {timeout_count}")
	print(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω")
	print(f"   üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {RESULTS_JSONL}")
	print(f"   üìã –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {REPORTS}/hf_inference_test_meta.json")
	print("\nüí° –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: --resume")


def main():
	parser = argparse.ArgumentParser()
	parser.add_argument('--max', type=int, default=400, help='–ú–∞–∫—Å. —á–∏—Å–ª–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∞')
	parser.add_argument('--concurrency', type=int, default=3, help='–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤')
	parser.add_argument('--timeout', type=int, default=45, help='–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞, —Å–µ–∫')
	parser.add_argument('--resume', action='store_true', help='–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –º–µ—Å—Ç–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ (–Ω–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ)')
	args = parser.parse_args()

	if not MODELS_JSONL.exists():
		print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: {MODELS_JSONL}")
		print("   –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–±–æ—Ä: python3 scripts/collect_hf_text2img_models.py")
		return 2

	if not HF_TOKEN:
		print("‚ö†Ô∏è –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è HF_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –±–µ–∑ —Ç–æ–∫–µ–Ω–∞ (–º–Ω–æ–≥–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å)")

	asyncio.run(run(args.max, args.concurrency, args.timeout, args.resume))
	return 0


if __name__ == '__main__':
	sys.exit(main())
