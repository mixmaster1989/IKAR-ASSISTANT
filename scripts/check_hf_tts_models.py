#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ TTS –º–æ–¥–µ–ª–µ–π Hugging Face Inference API.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  HF_API_TOKEN=... python3 scripts/check_hf_tts_models.py [--synthesize "–ü—Ä–∏–≤–µ—Ç, –ø—Ä–æ–≤–µ—Ä–∫–∞!" --save-dir temp/tts_samples]

–ü–æ–≤–µ–¥–µ–Ω–∏–µ:
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ scripts/hf_tts_models.json
- –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –¥–µ–ª–∞–µ—Ç HEAD/GET –∫ https://api-inference.huggingface.co/models/{model_id}
- –ü—Ä–∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–º --synthesize –ø—ã—Ç–∞–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å —Å–∏–Ω—Ç–µ–∑ –ø—Ä–æ—Å—Ç—ã–º JSON {"inputs": "..."}
  –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é.

–ó–∞–º–µ—á–∞–Ω–∏—è:
- –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤/—Ñ–æ—Ä–º–∞—Ç–æ–≤. –ó–¥–µ—Å—å –±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞.
- –î–ª—è RU –ª—É—á—à–µ –≤—Å–µ–≥–æ –æ–±—ã—á–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–µ–±—è coqui/XTTS-v2.
"""

import os
import json
import argparse
import time
from pathlib import Path
import requests


MODELS_FILE = Path(__file__).parent / 'hf_tts_models.json'
API_MODELS = 'https://api-inference.huggingface.co/models'
API_PIPELINE_TTS = 'https://api-inference.huggingface.co/pipeline/text-to-speech'


def load_models() -> list:
    with open(MODELS_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)


def check_model_metadata(session: requests.Session, token: str, model_id: str) -> dict:
    # –ü—ã—Ç–∞–µ–º—Å—è —Å–Ω–∞—á–∞–ª–∞ —á–µ—Ä–µ–∑ /models, –ø—Ä–∏ 404 –ø—Ä–æ–±—É–µ–º /pipeline/text-to-speech
    url_models = f"{API_MODELS}/{model_id}"
    headers = {"Authorization": f"Bearer {token}"} if token else {}
    resp = session.get(url_models, headers=headers, timeout=30)
    result = {
        'status_code': resp.status_code,
        'ok': resp.ok,
        'endpoint': 'models',
        'headers': dict(resp.headers),
        'json': safe_json(resp),
        'text': safe_text(resp)
    }
    if resp.status_code == 404:
        url_pipe = f"{API_PIPELINE_TTS}/{model_id}"
        resp2 = session.get(url_pipe, headers=headers, timeout=30)
        result = {
            'status_code': resp2.status_code,
            'ok': resp2.ok,
            'endpoint': 'pipeline/text-to-speech',
            'headers': dict(resp2.headers),
            'json': safe_json(resp2),
            'text': safe_text(resp2)
        }
    return result


def synthesize_sample(session: requests.Session, token: str, model_id: str, text: str, out_dir: Path) -> dict:
    # –ü—Ä–æ–±—É–µ–º POST –Ω–∞ /models, –ø—Ä–∏ 404 –ø—Ä–æ–±—É–µ–º /pipeline/text-to-speech
    url_models = f"{API_MODELS}/{model_id}"
    headers = {
        "Authorization": f"Bearer {token}" if token else "",
        "Content-Type": "application/json"
    }
    payload = {"inputs": text}
    start = time.time()
    resp = session.post(url_models, headers=headers, json=payload, timeout=60)
    elapsed = time.time() - start

    result = {
        'status_code': resp.status_code,
        'ok': resp.ok,
        'elapsed_s': round(elapsed, 2),
        'endpoint': 'models',
        'headers': dict(resp.headers)
    }

    if resp.status_code == 404:
        url_pipe = f"{API_PIPELINE_TTS}/{model_id}"
        start = time.time()
        resp = session.post(url_pipe, headers=headers, json=payload, timeout=60)
        elapsed = time.time() - start
        result.update({
            'status_code': resp.status_code,
            'ok': resp.ok,
            'elapsed_s': round(elapsed, 2),
            'endpoint': 'pipeline/text-to-speech',
            'headers': dict(resp.headers)
        })

    if resp.ok and resp.content:
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–π –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç
        ctype = resp.headers.get('content-type', '')
        ext = guess_ext(ctype)
        out_dir.mkdir(parents=True, exist_ok=True)
        out_path = out_dir / f"{model_id.replace('/', '_')}{ext}"
        with open(out_path, 'wb') as f:
            f.write(resp.content)
        result['saved'] = str(out_path)
        result['content_type'] = ctype
    else:
        result['json'] = safe_json(resp)
        result['text'] = safe_text(resp)

    return result


def guess_ext(content_type: str) -> str:
    if 'audio/wav' in content_type:
        return '.wav'
    if 'audio/mpeg' in content_type or 'audio/mp3' in content_type:
        return '.mp3'
    if 'audio/ogg' in content_type:
        return '.ogg'
    if 'application/json' in content_type:
        return '.json'
    return '.bin'


def safe_json(resp: requests.Response):
    try:
        return resp.json()
    except Exception:
        return None


def safe_text(resp: requests.Response):
    try:
        return resp.text
    except Exception:
        return None


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--synthesize', type=str, default=None, help='–¢–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞')
    parser.add_argument('--save-dir', type=str, default='temp/tts_samples', help='–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∞—É–¥–∏–æ')
    args = parser.parse_args()

    token = os.getenv('HF_API_KEY') or os.getenv('HF_API_TOKEN') or ''
    if not token:
        print('‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω HF_API_KEY/HF_API_TOKEN –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 401/403.')

    models = load_models()
    print(f"üîç –ú–æ–¥–µ–ª–µ–π –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ: {len(models)}")

    session = requests.Session()
    results = []

    for m in models:
        model_id = m['model_id']
        print(f"\n=== {model_id} ===")
        meta = check_model_metadata(session, token, model_id)
        print(f"META[{meta.get('endpoint')}] : {meta['status_code']} | ok={meta['ok']}")
        if meta.get('json'):
            j = meta['json']
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ—Ä–æ—Ç–∫–æ –≤–∞–∂–Ω–æ–µ
            if isinstance(j, dict):
                err = j.get('error') or j.get('message')
                if err:
                    print(f"  error: {err}")
        elif meta.get('text') and not meta['ok']:
            print(f"  text: {meta['text'][:120]}...")

        syn = None
        if args.synthesize:
            syn = synthesize_sample(session, token, model_id, args.synthesize, Path(args.save_dir))
            print(f"SYN[{syn.get('endpoint')}] : {syn['status_code']} | ok={syn['ok']} | {syn.get('elapsed_s','?')}s | saved={syn.get('saved')}")
            if syn.get('json'):
                j = syn['json']
                if isinstance(j, dict):
                    print(f"  json: {json.dumps(j)[:200]}...")
            elif syn.get('text') and not syn['ok']:
                print(f"  text: {syn['text'][:200]}...")

        results.append({
            'model_id': model_id,
            'meta': meta,
            'synthesis': syn
        })

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
    ok_meta = sum(1 for r in results if r['meta']['ok'])
    ok_syn = sum(1 for r in results if r.get('synthesis') and r['synthesis']['ok'])
    print(f"\nüìä –ò–¢–û–ì–û: META ok {ok_meta}/{len(results)} | SYN ok {ok_syn}/{sum(1 for r in results if r.get('synthesis'))}")


if __name__ == '__main__':
    main()


